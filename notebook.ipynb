{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ]
  },
  {
   "cell_type": "code",
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:13:24.297259Z",
     "start_time": "2025-12-11T06:13:24.285213Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "babb231646cfad15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:13:24.312464Z",
     "start_time": "2025-12-11T06:13:24.298083Z"
    }
   },
   "source": [
    "print(torch.backends.mps.is_available())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:13:24.365346Z",
     "start_time": "2025-12-11T06:13:24.323627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if False and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") # Apple GPU\n",
    "    print(\"Using MPS device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\") # Defaults to CPU\n",
    "    print(\"MPS device not found, using CPU\")\n",
    "\n",
    "# Example: Move a tensor or model to the MPS device\n",
    "class TwoBranch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model = nn.LSTM(input_size=3, hidden_size=4, batch_first=False, num_layers=1).to(device)\n",
    "        self.left = model\n",
    "        self.right = model\n",
    "        self.combine = nn.Linear(8, 4).to(device)\n",
    "\n",
    "    def forward(self, x_left, x_right):\n",
    "        _, (l_h, _) = self.left(x_left)\n",
    "        _, (r_h, _) = self.right(x_right)\n",
    "\n",
    "        l = l_h[-1]  # last layer, shape: (batch, hidden_size)\n",
    "        r = r_h[-1]\n",
    "\n",
    "        cat = torch.cat([l, r], dim=-1)  # shape: (batch, 10)\n",
    "        return self.combine(cat)          # shape: (batch, 10) -> Linear(10,1) -> (batch,1)\n",
    "class BigModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.branch = TwoBranch()\n",
    "        self.rest = nn.Sequential(\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(4, 4),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(4, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 1)\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x_left, x_right):\n",
    "        x = self.branch(x_left, x_right)\n",
    "        return self.rest(x)\n",
    "model2=BigModel().to(device)\n",
    "\n"
   ],
   "id": "2144e2a1fac24e8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device not found, using CPU\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "2d151ea48ca597e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "ad47713dbc1ce9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:13:24.387290Z",
     "start_time": "2025-12-11T06:13:24.365823Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "batch = 32\n",
    "seq_len = 64\n",
    "\n",
    "x_left  = torch.randn(seq_len, batch, 3, device=device)\n",
    "x_right = torch.randn(seq_len, batch, 3, device=device)\n",
    "\n",
    "# labels depend on problem:\n",
    "y = torch.randn(batch, 1, device=device)  # regression\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbatch = 32\\nseq_len = 64\\n\\nx_left  = torch.randn(seq_len, batch, 3, device=device)\\nx_right = torch.randn(seq_len, batch, 3, device=device)\\n\\n# labels depend on problem:\\ny = torch.randn(batch, 1, device=device)  # regression\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "662ce026650504db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:13:24.408162Z",
     "start_time": "2025-12-11T06:13:24.387925Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "files = glob.glob(\"data/*.json\")\n",
    "people = []\n",
    "for file in files:\n",
    "    df = pd.read_json(file)\n",
    "    drawings = []\n",
    "    for drawing in df.values:\n",
    "        points = drawing[0][0][\"points\"]\n",
    "        triples = [(point[\"x\"], point[\"y\"], point[\"time\"]) for point in points]\n",
    "        drawings.append(triples)\n",
    "    people.append(drawings)\n",
    "\n",
    "\n",
    "data = people\n"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "7cf159954d81a8ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:13:24.425790Z",
     "start_time": "2025-12-11T06:13:24.408540Z"
    }
   },
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "out_path = Path(\"output/data.json\")\n",
    "\n",
    "out_path.write_text(json.dumps(data, indent=2))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485185"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "e54d062d01d46332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:13:24.433107Z",
     "start_time": "2025-12-11T06:13:24.426166Z"
    }
   },
   "source": [
    "out_path = Path(\"output/data.json\")\n",
    "loaded = json.load(out_path.open())"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "id": "421c884230872855",
   "metadata": {},
   "source": [
    "Looking at your code, I can see several issues with the train/test split creation:\n",
    "\n",
    "1. You're using `len(left)` but `left` is not defined - it should be `len(paired)`\n",
    "2. You're overwriting `leftTrain`, `rightTrain`, and `yTrain` instead of creating separate test variables\n",
    "3. The variable naming is inconsistent\n",
    "\n",
    "Here's the fixed code for your cell:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2cc0a90f82c0158e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:13:24.478668Z",
     "start_time": "2025-12-11T06:13:24.433352Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "training: list[list[list[tuple[int, int, int]]]] = loaded\n",
    "pairedDeep = [[torch.tensor(drawing, device=device) for drawing in drawings] for drawings in training]\n",
    "paired: list[torch.Tensor] = []\n",
    "personIDs: list[int] = []\n",
    "for personID, person in enumerate(pairedDeep):\n",
    "    person = [drawing[:-1]-drawing[1:] for drawing in person]\n",
    "    a = [personID] * len(person)\n",
    "    personIDs.extend(a)\n",
    "    paired.extend([((i[:, :] - i.min(dim=0, keepdim=True).values) / (\n",
    "    (i.max(dim=0, keepdim=True).values - i.min(dim=0, keepdim=True).values)))*2-0.5 for i in person])\n",
    "personIDs = np.array(personIDs)\n",
    "lengths = torch.tensor([len(s) for s in paired])\n",
    "\n",
    "\n",
    "def packPad(pairs: list[torch.Tensor], lengths: torch.Tensor, indeces):\n",
    "    padded = nn.utils.rnn.pad_sequence([pairs[i].to(device) for i in indeces], batch_first=True).to(device)\n",
    "    lengths = lengths[indeces]\n",
    "    packed = nn.utils.rnn.pack_padded_sequence(\n",
    "        padded,\n",
    "        lengths,\n",
    "        batch_first=True,\n",
    "        enforce_sorted=False\n",
    "    ).float().to(device)\n",
    "    return packed\n",
    "\n",
    "\n",
    "\n",
    "# Split at PERSON level to prevent any leakage\n",
    "n_people = len(pairedDeep)\n",
    "split_person_idx = int(n_people * 0.8)\n",
    "\n",
    "# Get all indices for train people and test people\n",
    "train_person_indices = []\n",
    "test_person_indices = []\n",
    "\n",
    "for person_id in range(n_people):\n",
    "    person_mask = personIDs == person_id\n",
    "    person_samples = np.where(person_mask)[0]\n",
    "\n",
    "    if person_id < split_person_idx:\n",
    "        train_person_indices.extend(person_samples)\n",
    "    else:\n",
    "        test_person_indices.extend(person_samples)\n",
    "\n",
    "train_person_indices = np.array(train_person_indices)\n",
    "test_person_indices = np.array(test_person_indices)\n",
    "\n",
    "print(f\"Training people: 0-{split_person_idx-1}\")\n",
    "print(f\"Test people: {split_person_idx}-{n_people-1}\")\n",
    "print(f\"Train samples: {len(train_person_indices)}\")\n",
    "print(f\"Test samples: {len(test_person_indices)}\")\n",
    "\n",
    "\n",
    "def generate_balanced_pairs(indices, n_pairs, personIDs):\n",
    "    \"\"\"Generate 50/50 same-person vs different-person pairs\"\"\"\n",
    "    left_indices = []\n",
    "    right_indices = []\n",
    "\n",
    "    n_same = n_pairs // 2\n",
    "    n_diff = n_pairs - n_same\n",
    "\n",
    "    # Same-person pairs\n",
    "    for _ in range(n_same):\n",
    "        idx = np.random.choice(indices)\n",
    "        person_id = personIDs[idx]\n",
    "        same_person_mask = personIDs[indices] == person_id\n",
    "        same_person_indices = indices[same_person_mask]\n",
    "\n",
    "        if len(same_person_indices) > 1:\n",
    "            pair = np.random.choice(same_person_indices, size=2, replace=False)\n",
    "            left_indices.append(pair[0])\n",
    "            right_indices.append(pair[1])\n",
    "        else:\n",
    "            left_indices.append(idx)\n",
    "            right_indices.append(idx)\n",
    "\n",
    "    # Different-person pairs\n",
    "    for _ in range(n_diff):\n",
    "        idx1 = np.random.choice(indices)\n",
    "        person1 = personIDs[idx1]\n",
    "        diff_person_mask = personIDs[indices] != person1\n",
    "        diff_person_indices = indices[diff_person_mask]\n",
    "\n",
    "        if len(diff_person_indices) > 0:\n",
    "            idx2 = np.random.choice(diff_person_indices)\n",
    "            left_indices.append(idx1)\n",
    "            right_indices.append(idx2)\n",
    "        else:\n",
    "            left_indices.append(idx1)\n",
    "            right_indices.append(np.random.choice(indices))\n",
    "\n",
    "    return np.array(left_indices), np.array(right_indices)\n",
    "\n",
    "\n",
    "# Generate balanced pairs\n",
    "n_train_pairs = len(train_person_indices) * 3  # Reduce multiplier for stability\n",
    "n_test_pairs = len(test_person_indices) * 3\n",
    "\n",
    "pLT, pRT = generate_balanced_pairs(train_person_indices, n_train_pairs, personIDs)\n",
    "pLTest, pRTest = generate_balanced_pairs(test_person_indices, n_test_pairs, personIDs)\n",
    "\n",
    "pairedNP = paired\n",
    "lengthsNP = lengths\n",
    "leftTrain = packPad(pairedNP, lengthsNP, pLT).to(device)\n",
    "rightTrain = packPad(pairedNP, lengthsNP, pRT).to(device)\n",
    "yTrain = (torch.tensor(personIDs[pLT] == personIDs[pRT])\n",
    "          .reshape((-1, 1))\n",
    "          .to(device, dtype=torch.float32))\n",
    "\n",
    "leftTest = packPad(pairedNP, lengthsNP, pLTest).to(device)\n",
    "rightTest = packPad(pairedNP, lengthsNP, pRTest).to(device)\n",
    "yTest = (torch.tensor(personIDs[pLTest] == personIDs[pRTest])\n",
    "         .reshape((-1, 1))\n",
    "         .to(device, dtype=torch.float32))\n",
    "\n",
    "print(f\"\\nTrain: {(yTrain == 1).sum().item() / len(yTrain) * 100:.1f}% same person\")\n",
    "print(f\"Test:  {(yTest == 1).sum().item() / len(yTest) * 100:.1f}% same person\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training people: 0-7\n",
      "Test people: 8-9\n",
      "Train samples: 134\n",
      "Test samples: 33\n",
      "\n",
      "Train: 50.0% same person\n",
      "Test:  49.5% same person\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "e7c980897c1921d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:13:24.482689Z",
     "start_time": "2025-12-11T06:13:24.479Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "40e3fc2b044139f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:13:24.499887Z",
     "start_time": "2025-12-11T06:13:24.482906Z"
    }
   },
   "source": "str(((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean().item())",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5050504803657532'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "459fc8e5ae926f03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:13:24.513948Z",
     "start_time": "2025-12-11T06:13:24.500306Z"
    }
   },
   "source": [
    "model2.branch.left.all_weights"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Parameter containing:\n",
       "  tensor([[ 0.1634,  0.2514,  0.3924],\n",
       "          [-0.4762, -0.0926,  0.4312],\n",
       "          [-0.3831,  0.4893, -0.3971],\n",
       "          [ 0.2921,  0.4923, -0.2561],\n",
       "          [-0.1813, -0.3747, -0.2108],\n",
       "          [-0.1567, -0.4283,  0.2375],\n",
       "          [ 0.3409,  0.2913,  0.3565],\n",
       "          [ 0.3852,  0.1670, -0.1862],\n",
       "          [-0.3056, -0.2157, -0.4547],\n",
       "          [ 0.0259, -0.4679,  0.4669],\n",
       "          [-0.1497, -0.1768,  0.1819],\n",
       "          [ 0.0415,  0.4443, -0.1662],\n",
       "          [-0.1289, -0.2218, -0.4463],\n",
       "          [ 0.0703, -0.1757, -0.1563],\n",
       "          [ 0.0690,  0.0286,  0.4764],\n",
       "          [ 0.2091,  0.4792,  0.1672]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1333,  0.0458,  0.0602, -0.3342],\n",
       "          [-0.3707, -0.0972,  0.3718, -0.1523],\n",
       "          [-0.1391, -0.1258, -0.1378, -0.1478],\n",
       "          [-0.3191, -0.1683,  0.4646,  0.3791],\n",
       "          [-0.2949,  0.2273,  0.1897,  0.3721],\n",
       "          [ 0.1991, -0.2522, -0.3691, -0.0788],\n",
       "          [-0.2792,  0.1298,  0.4373, -0.3836],\n",
       "          [ 0.4887, -0.2566, -0.3096, -0.4731],\n",
       "          [ 0.4282,  0.4544,  0.1312, -0.1848],\n",
       "          [ 0.0948,  0.1677, -0.1153, -0.4975],\n",
       "          [ 0.1822,  0.3664,  0.3115, -0.3661],\n",
       "          [-0.0675,  0.4152,  0.2828,  0.2526],\n",
       "          [-0.2023, -0.3424,  0.0030,  0.0878],\n",
       "          [-0.2672, -0.2113,  0.0709,  0.1192],\n",
       "          [-0.0783, -0.0917,  0.0931,  0.3202],\n",
       "          [ 0.3428, -0.2733,  0.0348, -0.3831]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.4113,  0.0598, -0.3733, -0.2142, -0.2562,  0.1163,  0.3656, -0.1495,\n",
       "           0.0760, -0.0536, -0.1774,  0.0788, -0.4816, -0.3886,  0.2733,  0.1268],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.3395, -0.3019,  0.1752, -0.4009, -0.3279,  0.3006, -0.4171, -0.2231,\n",
       "           0.4862, -0.0414,  0.4529, -0.3519, -0.1896,  0.4405, -0.2458, -0.0892],\n",
       "         requires_grad=True)]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "3661cc14ec4e9e27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:14:51.580496Z",
     "start_time": "2025-12-11T06:14:51.564002Z"
    }
   },
   "source": [
    "epochs = 1000\n",
    "# BCELogits with L2 reg\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model2.parameters(), lr=0.1, weight_decay=1e-1)\n"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "id": "da38f55d3403291d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:16:32.941913Z",
     "start_time": "2025-12-11T06:16:21.214450Z"
    }
   },
   "source": [
    "annealer = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    epoch_loss = 0.0\n",
    "    output = model2(leftTrain, rightTrain)\n",
    "    loss = criterion(output, yTrain)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    annealer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss += loss.item() * yTrain.size(0)\n",
    "\n",
    "    # average loss for the epoch\n",
    "    epoch_loss /= len(leftTrain)\n",
    "\n",
    "\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch:3d} – loss: {epoch_loss:.4f} - fPC {((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean():.4f}, {((model2(leftTrain, rightTrain)>0)==(yTrain>0.5)).float().mean():.4f}\")\n",
    "\n",
    "model2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 – loss: 22.6628 - fPC 0.7576, 0.9502\n",
      "Epoch  10 – loss: 44.6237 - fPC 0.5354, 0.8134\n",
      "Epoch  20 – loss: 44.5145 - fPC 0.5657, 0.8458\n",
      "Epoch  30 – loss: 40.0377 - fPC 0.7374, 0.8557\n",
      "Epoch  40 – loss: 37.5079 - fPC 0.7980, 0.8706\n",
      "Epoch  50 – loss: 36.3260 - fPC 0.8182, 0.8682\n",
      "Epoch  60 – loss: 36.8000 - fPC 0.8788, 0.8682\n",
      "Epoch  70 – loss: 35.2756 - fPC 0.7980, 0.8756\n",
      "Epoch  80 – loss: 33.9999 - fPC 0.8081, 0.8881\n",
      "Epoch  90 – loss: 33.0253 - fPC 0.7980, 0.8955\n",
      "Epoch 100 – loss: 35.5642 - fPC 0.8586, 0.8731\n",
      "Epoch 110 – loss: 34.0721 - fPC 0.8687, 0.8806\n",
      "Epoch 120 – loss: 33.0232 - fPC 0.8788, 0.8781\n",
      "Epoch 130 – loss: 31.6479 - fPC 0.8788, 0.8955\n",
      "Epoch 140 – loss: 30.5784 - fPC 0.9293, 0.9005\n",
      "Epoch 150 – loss: 29.1497 - fPC 0.9394, 0.9154\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[60]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      5\u001B[39m output = model2(leftTrain, rightTrain)\n\u001B[32m      6\u001B[39m loss = criterion(output, yTrain)\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m optimizer.step()\n\u001B[32m     10\u001B[39m annealer.step()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.13/site-packages/torch/_tensor.py:625\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    615\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    616\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    617\u001B[39m         Tensor.backward,\n\u001B[32m    618\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    623\u001B[39m         inputs=inputs,\n\u001B[32m    624\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m625\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    626\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    627\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    349\u001B[39m     retain_graph = create_graph\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    353\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m354\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    362\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    839\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    840\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m841\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    842\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    843\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    844\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    845\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:26:25.353221Z",
     "start_time": "2025-12-11T06:26:24.999446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    epoch_loss = 0.0\n",
    "    output = model2(leftTrain, rightTrain)\n",
    "    loss = criterion(output, yTrain)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    annealer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss += loss.item() * yTrain.size(0)\n",
    "\n",
    "    # average loss for the epoch\n",
    "    epoch_loss /= len(leftTrain)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Epoch {epoch:3d} – loss: {epoch_loss:.4f} - fPC {((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean():.4f}, {((model2(leftTrain, rightTrain)>0)==(yTrain>0.5)).float().mean():.4f}\")"
   ],
   "id": "508c60fce524d6fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4 – loss: 69.5303 - fPC 0.4848, 0.4602\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:16:18.565545Z",
     "start_time": "2025-12-11T06:16:18.557417Z"
    }
   },
   "cell_type": "code",
   "source": "model2 = model",
   "id": "eb66ba04a8859b0f",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:26:10.196942Z",
     "start_time": "2025-12-11T06:26:10.188525Z"
    }
   },
   "cell_type": "code",
   "source": "model = model2",
   "id": "3266c15fc9555c07",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:22:14.926252Z",
     "start_time": "2025-12-11T06:22:14.914820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ckpt = {\n",
    "    'epoch'         : epoch,                     # current epoch number\n",
    "    'model_state'   : model.state_dict(),        # model parameters\n",
    "    'optimizer_state': optimizer.state_dict(),   # optimizer internals\n",
    "    'scheduler_state': annealer.state_dict() if annealer else None,\n",
    "}\n",
    "torch.save(ckpt, 'model.pt')\n",
    "torch.save(model.state_dict(), 'model_weights.pt')\n"
   ],
   "id": "bb5756b283949eec",
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "id": "a2ffde47d0a4b526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:26:33.271231Z",
     "start_time": "2025-12-11T06:26:33.252966Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "def confusion_rates(yhat: torch.Tensor, y: torch.Tensor):\n",
    "    tp = (yhat == 1) & (y == 1)\n",
    "    tn = (yhat == 0) & (y == 0)\n",
    "    fp = (yhat == 1) & (y == 0)\n",
    "    fn = (yhat == 0) & (y == 1)\n",
    "\n",
    "    TP = int(tp.sum().item())\n",
    "    TN = int(tn.sum().item())\n",
    "    FP = int(fp.sum().item())\n",
    "    FN = int(fn.sum().item())\n",
    "\n",
    "    eps = 1e-12\n",
    "    TPR = TP / (TP + FN + eps)   # recall / sensitivity\n",
    "    TNR = TN / (TN + FP + eps)   # specificity\n",
    "    FPR = FP / (FP + TN + eps)   # 1 - specificity\n",
    "    FNR = FN / (FN + TP + eps)   # 1 - recall\n",
    "\n",
    "    return {\"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
    "            \"TPR\": TPR, \"TNR\": TNR, \"FPR\": FPR, \"FNR\": FNR}\n",
    "\n",
    "def metrics(model, leftTest, rightTest, yTest):\n",
    "    yhat = model(leftTest, rightTest) > 0\n",
    "    y = yTest\n",
    "    return confusion_rates(yhat, y)\n",
    "\n",
    "res = metrics(model2, leftTest, rightTest, yTest)\n",
    "\n",
    "print(f\"True Positive Rate (Recall) : {res['TPR']:.4f}; TP : {res['TP']}\")\n",
    "print(f\"True Negative Rate (Spec.)  : {res['TNR']:.4f}; TN : {res['TN']}\")\n",
    "print(f\"False Positive Rate         : {res['FPR']:.4f}; FP : {res['FP']}\")\n",
    "print(f\"False Negative Rate         : {res['FNR']:.4f}; FN : {res['FN']}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate (Recall) : 0.0204; TP : 1\n",
      "True Negative Rate (Spec.)  : 0.9400; TN : 47\n",
      "False Positive Rate         : 0.0600; FP : 3\n",
      "False Negative Rate         : 0.9796; FN : 48\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:26:44.125864Z",
     "start_time": "2025-12-11T06:26:44.091168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weights = torch.load('model_weights.pt', map_location=device)\n",
    "model_new = BigModel()          # the same class you used during training\n",
    "model_new.load_state_dict(weights)\n",
    "model_new.to(device)\n",
    "\n",
    "res = metrics(model_new, leftTest, rightTest, yTest)\n",
    "\n",
    "print(f\"True Positive Rate (Recall) : {res['TPR']:.4f}; TP : {res['TP']}\")\n",
    "print(f\"True Negative Rate (Spec.)  : {res['TNR']:.4f}; TN : {res['TN']}\")\n",
    "print(f\"False Positive Rate         : {res['FPR']:.4f}; FP : {res['FP']}\")\n",
    "print(f\"False Negative Rate         : {res['FNR']:.4f}; FN : {res['FN']}\")"
   ],
   "id": "eb4cceaaa64eed94",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate (Recall) : 0.8163; TP : 40\n",
      "True Negative Rate (Spec.)  : 0.9800; TN : 49\n",
      "False Positive Rate         : 0.0200; FP : 1\n",
      "False Negative Rate         : 0.1837; FN : 9\n"
     ]
    }
   ],
   "execution_count": 100
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
