{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ]
  },
  {
   "cell_type": "code",
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:51:45.982382Z",
     "start_time": "2025-12-12T00:51:45.936694Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from numpy.random.mtrand import permutation"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "babb231646cfad15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:51:46.012005Z",
     "start_time": "2025-12-12T00:51:45.983521Z"
    }
   },
   "source": [
    "print(torch.backends.mps.is_available())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:51:46.031216Z",
     "start_time": "2025-12-12T00:51:46.012941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cpu\") # Defaults to CPU\n",
    "\n",
    "# Example: Move a tensor or model to the MPS device\n",
    "class TwoBranch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model = nn.LSTM(input_size=3, hidden_size=8, batch_first=False, dropout=0.2, num_layers=1).to(device)\n",
    "        self.left = model\n",
    "        self.right = model\n",
    "        self.combine = nn.Linear(16, 9).to(device)\n",
    "        nn.init.xavier_uniform_(model.weight_ih_l0)\n",
    "        nn.init.xavier_uniform_(model.weight_hh_l0)\n",
    "    def forward(self, x_left, x_right):\n",
    "        _, (l_h, _) = self.left(x_left)\n",
    "        _, (r_h, _) = self.right(x_right)\n",
    "\n",
    "        l = l_h[-1]  # last layer, shape: (batch, hidden_size)\n",
    "        r = r_h[-1]\n",
    "\n",
    "        cat = torch.cat([l, r], dim=-1)  # shape: (batch, 10)\n",
    "        return self.combine(cat)          # shape: (batch, 10) -> Linear(10,1) -> (batch,1)\n",
    "class BigModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.branch = TwoBranch()\n",
    "        self.rest = nn.Sequential(\n",
    "            nn.Linear(9, 9),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(9, 9),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(9, 1)\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x_left, x_right):\n",
    "        x = self.branch(x_left, x_right)\n",
    "        return self.rest(x)\n",
    "model2=BigModel().to(device)\n",
    "\n"
   ],
   "id": "2144e2a1fac24e8b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/everettwilber/PyCharmMiscProject/.venv/lib/python3.13/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "2d151ea48ca597e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "ad47713dbc1ce9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:51:46.046777Z",
     "start_time": "2025-12-12T00:51:46.031551Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "batch = 32\n",
    "seq_len = 64\n",
    "\n",
    "x_left  = torch.randn(seq_len, batch, 3, device=device)\n",
    "x_right = torch.randn(seq_len, batch, 3, device=device)\n",
    "\n",
    "# labels depend on problem:\n",
    "y = torch.randn(batch, 1, device=device)  # regression\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbatch = 32\\nseq_len = 64\\n\\nx_left  = torch.randn(seq_len, batch, 3, device=device)\\nx_right = torch.randn(seq_len, batch, 3, device=device)\\n\\n# labels depend on problem:\\ny = torch.randn(batch, 1, device=device)  # regression\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "662ce026650504db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:51:46.098631Z",
     "start_time": "2025-12-12T00:51:46.054997Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "files = glob.glob(\"data/*.json\")\n",
    "people = []\n",
    "for file in files:\n",
    "    df = pd.read_json(file)\n",
    "    drawings = []\n",
    "    for drawing in df.values:\n",
    "        drawing = drawing[0]\n",
    "        allTriples = []\n",
    "        for stroke in drawing:\n",
    "            points = stroke[\"points\"]\n",
    "            triples = [(point[\"x\"], point[\"y\"], point[\"time\"]) for point in points]\n",
    "            allTriples.extend(triples)\n",
    "        drawings.append(allTriples)\n",
    "    people.append(drawings)\n",
    "\n",
    "\n",
    "data = people\n"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "7cf159954d81a8ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:51:46.113421Z",
     "start_time": "2025-12-12T00:51:46.098858Z"
    }
   },
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "out_path = Path(\"output/data.json\")\n",
    "\n",
    "out_path.write_text(json.dumps(data, indent=2))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983106"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "e54d062d01d46332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:51:46.121433Z",
     "start_time": "2025-12-12T00:51:46.113851Z"
    }
   },
   "source": [
    "out_path = Path(\"output/data.json\")\n",
    "loaded = json.load(out_path.open())"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "2cc0a90f82c0158e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:51:46.180536Z",
     "start_time": "2025-12-12T00:51:46.121673Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "training: list[list[list[tuple[int, int, int]]]] = loaded\n",
    "pairedDeep = [[torch.tensor(drawing, device=device) for drawing in drawings] for drawings in training]\n",
    "paired: list[torch.Tensor] = []\n",
    "personIDs: list[int] = []\n",
    "for personID, person in enumerate(pairedDeep):\n",
    "    person = [drawing[:-1]-drawing[1:] for drawing in person]\n",
    "    a = [personID] * len(person)\n",
    "    personIDs.extend(a)\n",
    "    paired.extend([((i[:, :] - i.min(dim=0, keepdim=True).values) / (\n",
    "    (i.max(dim=0, keepdim=True).values - i.min(dim=0, keepdim=True).values)))*2-0.5 for i in person])\n",
    "personIDs = np.array(personIDs)\n",
    "lengths = torch.tensor([len(s) for s in paired])\n",
    "\n",
    "\n",
    "def packPad(pairs: list[torch.Tensor], lengths: torch.Tensor, indeces):\n",
    "    padded = nn.utils.rnn.pad_sequence([pairs[i].to(device) for i in indeces], batch_first=True).to(device)\n",
    "    lengths = lengths[indeces]\n",
    "    packed = nn.utils.rnn.pack_padded_sequence(\n",
    "        padded,\n",
    "        lengths,\n",
    "        batch_first=True,\n",
    "        enforce_sorted=False\n",
    "    ).float().to(device)\n",
    "    return packed\n",
    "\n",
    "\n",
    "\n",
    "# Split at PERSON level to prevent any leakage\n",
    "n_people = len(pairedDeep)\n",
    "split_person_idx = int(n_people * 0.8)\n",
    "\n",
    "# Get all indices for train people and test people\n",
    "train_person_indices = []\n",
    "test_person_indices = []\n",
    "\n",
    "for person_id in range(n_people):\n",
    "    person_mask = personIDs == person_id\n",
    "    person_samples = np.where(person_mask)[0]\n",
    "\n",
    "    if person_id < split_person_idx:\n",
    "        train_person_indices.extend(person_samples)\n",
    "    else:\n",
    "        test_person_indices.extend(person_samples)\n",
    "\n",
    "train_person_indices = np.array(train_person_indices)\n",
    "test_person_indices = np.array(test_person_indices)\n",
    "\n",
    "print(f\"Training people: 0-{split_person_idx-1}\")\n",
    "print(f\"Test people: {split_person_idx}-{n_people-1}\")\n",
    "print(f\"Train samples: {len(train_person_indices)}\")\n",
    "print(f\"Test samples: {len(test_person_indices)}\")\n",
    "\n",
    "\n",
    "def generate_balanced_pairs(indices, n_pairs, personIDs):\n",
    "    \"\"\"Generate 50/50 same-person vs different-person pairs\"\"\"\n",
    "    left_indices = []\n",
    "    right_indices = []\n",
    "\n",
    "    n_same = n_pairs // 2\n",
    "    n_diff = n_pairs - n_same\n",
    "\n",
    "    # Same-person pairs\n",
    "    for _ in range(n_same):\n",
    "        idx = np.random.choice(indices)\n",
    "        person_id = personIDs[idx]\n",
    "        same_person_mask = personIDs[indices] == person_id\n",
    "        same_person_indices = indices[same_person_mask]\n",
    "\n",
    "        if len(same_person_indices) > 1:\n",
    "            pair = np.random.choice(same_person_indices, size=2, replace=False)\n",
    "            left_indices.append(pair[0])\n",
    "            right_indices.append(pair[1])\n",
    "        else:\n",
    "            left_indices.append(idx)\n",
    "            right_indices.append(idx)\n",
    "\n",
    "    # Different-person pairs\n",
    "    for _ in range(n_diff):\n",
    "        idx1 = np.random.choice(indices)\n",
    "        person1 = personIDs[idx1]\n",
    "        diff_person_mask = personIDs[indices] != person1\n",
    "        diff_person_indices = indices[diff_person_mask]\n",
    "\n",
    "        if len(diff_person_indices) > 0:\n",
    "            idx2 = np.random.choice(diff_person_indices)\n",
    "            left_indices.append(idx1)\n",
    "            right_indices.append(idx2)\n",
    "        else:\n",
    "            left_indices.append(idx1)\n",
    "            right_indices.append(np.random.choice(indices))\n",
    "\n",
    "    return np.array(left_indices), np.array(right_indices)\n",
    "\n",
    "\n",
    "# Generate balanced pairs\n",
    "n_train_pairs = len(train_person_indices)  # Reduce multiplier for stability\n",
    "n_test_pairs = len(test_person_indices)\n",
    "\n",
    "pLT, pRT = generate_balanced_pairs(train_person_indices, n_train_pairs, personIDs)\n",
    "pLTest, pRTest = generate_balanced_pairs(test_person_indices, n_test_pairs, personIDs)\n",
    "\n",
    "pairedNP = paired\n",
    "lengthsNP = lengths\n",
    "leftTrain = packPad(pairedNP, lengthsNP, pLT).to(device)\n",
    "rightTrain = packPad(pairedNP, lengthsNP, pRT).to(device)\n",
    "yTrain = (torch.tensor(personIDs[pLT] == personIDs[pRT])\n",
    "          .reshape((-1, 1))\n",
    "          .to(device, dtype=torch.float32))\n",
    "\n",
    "leftTest = packPad(pairedNP, lengthsNP, pLTest).to(device)\n",
    "rightTest = packPad(pairedNP, lengthsNP, pRTest).to(device)\n",
    "yTest = (torch.tensor(personIDs[pLTest] == personIDs[pRTest])\n",
    "         .reshape((-1, 1))\n",
    "         .to(device, dtype=torch.float32))\n",
    "\n",
    "print(f\"\\nTrain: {(yTrain == 1).sum().item() / len(yTrain) * 100:.1f}% same person\")\n",
    "print(f\"Test:  {(yTest == 1).sum().item() / len(yTest) * 100:.1f}% same person\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training people: 0-15\n",
      "Test people: 16-20\n",
      "Train samples: 214\n",
      "Test samples: 63\n",
      "\n",
      "Train: 50.0% same person\n",
      "Test:  49.2% same person\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "e7c980897c1921d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:51:46.183802Z",
     "start_time": "2025-12-12T00:51:46.180832Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "40e3fc2b044139f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:51:46.201662Z",
     "start_time": "2025-12-12T00:51:46.183994Z"
    }
   },
   "source": "str(((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean().item())",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4920634925365448'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "459fc8e5ae926f03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:51:46.212768Z",
     "start_time": "2025-12-12T00:51:46.201991Z"
    }
   },
   "source": [
    "model2.branch.left.all_weights"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Parameter containing:\n",
       "  tensor([[-0.1991,  0.2518, -0.0761],\n",
       "          [-0.0963,  0.3227,  0.0356],\n",
       "          [-0.3188,  0.0726, -0.4008],\n",
       "          [ 0.0371, -0.0477, -0.0532],\n",
       "          [-0.0121, -0.0535,  0.1920],\n",
       "          [ 0.3320, -0.0901, -0.0172],\n",
       "          [ 0.0936,  0.2359,  0.1472],\n",
       "          [ 0.3727,  0.2179, -0.0137],\n",
       "          [ 0.3522,  0.2123, -0.2217],\n",
       "          [ 0.2881, -0.3475,  0.3999],\n",
       "          [ 0.1589,  0.3211, -0.2994],\n",
       "          [-0.0474,  0.2162, -0.2767],\n",
       "          [-0.1416,  0.0890,  0.1737],\n",
       "          [-0.1305, -0.0894, -0.1839],\n",
       "          [-0.2267, -0.1595,  0.3415],\n",
       "          [ 0.3951,  0.3343,  0.1450],\n",
       "          [ 0.2372,  0.3843,  0.2295],\n",
       "          [-0.3328, -0.0613,  0.2366],\n",
       "          [-0.3165, -0.2280, -0.1089],\n",
       "          [ 0.0805, -0.1476, -0.1801],\n",
       "          [-0.3160, -0.1995,  0.2247],\n",
       "          [-0.0153,  0.3403, -0.3626],\n",
       "          [ 0.1784,  0.0658, -0.2697],\n",
       "          [-0.3799,  0.1366,  0.2685],\n",
       "          [-0.3289,  0.0187, -0.2472],\n",
       "          [-0.3170, -0.0825,  0.0228],\n",
       "          [-0.0011, -0.3162,  0.2329],\n",
       "          [ 0.3761, -0.0499,  0.1681],\n",
       "          [-0.2121, -0.3741, -0.1010],\n",
       "          [-0.1387,  0.0786,  0.3081],\n",
       "          [-0.0786,  0.2984, -0.2003],\n",
       "          [ 0.1924, -0.3153, -0.2454]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1186,  0.2853, -0.2730,  0.3798, -0.2121, -0.0075,  0.3695, -0.2345],\n",
       "          [ 0.1980,  0.0634,  0.1554, -0.1424,  0.3107,  0.3270, -0.1657,  0.0103],\n",
       "          [ 0.1026,  0.3210, -0.0043, -0.0244, -0.3709,  0.2758,  0.1403, -0.3122],\n",
       "          [ 0.3562,  0.2549, -0.1201,  0.0632,  0.1760,  0.3139,  0.2439,  0.1863],\n",
       "          [ 0.3516, -0.0186, -0.2252,  0.1896, -0.2236,  0.0305,  0.2851,  0.1714],\n",
       "          [-0.2363,  0.1863,  0.1429, -0.1342, -0.0423, -0.3137, -0.2255, -0.0191],\n",
       "          [ 0.0028,  0.2680,  0.3863, -0.2212, -0.3540,  0.1681, -0.3386, -0.2721],\n",
       "          [ 0.0531, -0.3652,  0.2321,  0.0492, -0.3039, -0.3838,  0.2703,  0.1442],\n",
       "          [-0.1966,  0.1340, -0.0871, -0.3020,  0.0088, -0.2805,  0.1970, -0.0462],\n",
       "          [-0.0252,  0.3379,  0.0582, -0.1019, -0.0981,  0.3598,  0.1074, -0.2930],\n",
       "          [ 0.1444, -0.3550,  0.3096,  0.3173,  0.0704,  0.1162, -0.2502, -0.0235],\n",
       "          [-0.3150,  0.0724,  0.1675, -0.0284, -0.2938, -0.1057, -0.1250,  0.3418],\n",
       "          [-0.2556,  0.2963, -0.3759, -0.0735,  0.2118,  0.3812, -0.2177,  0.0080],\n",
       "          [-0.2060, -0.1328,  0.3287,  0.3381,  0.0750,  0.1766, -0.2063, -0.2973],\n",
       "          [ 0.0350,  0.1777, -0.2630, -0.2361, -0.1797,  0.3640, -0.0635,  0.2665],\n",
       "          [-0.3707,  0.1089,  0.0783,  0.2591,  0.1676,  0.2069,  0.1659, -0.1315],\n",
       "          [-0.0642,  0.0639,  0.3818,  0.1408,  0.0642,  0.0866, -0.1193, -0.1066],\n",
       "          [ 0.3450, -0.3105,  0.3598,  0.3022,  0.2232, -0.2472,  0.1509,  0.3414],\n",
       "          [ 0.0403, -0.1343,  0.1542, -0.1538,  0.1283, -0.2989, -0.1507, -0.3781],\n",
       "          [ 0.2910, -0.0723, -0.3108, -0.3094, -0.2482, -0.0576, -0.1313, -0.3545],\n",
       "          [-0.2353,  0.2078, -0.3048, -0.2428, -0.0224,  0.2768, -0.0467, -0.3159],\n",
       "          [-0.3230, -0.0971, -0.3440, -0.2250,  0.2387,  0.2324, -0.3791,  0.1973],\n",
       "          [-0.3770,  0.1279,  0.2147, -0.0041, -0.1771,  0.2179,  0.2590, -0.2284],\n",
       "          [-0.3228, -0.2322, -0.3146,  0.1724,  0.3833,  0.3867,  0.3158, -0.1405],\n",
       "          [ 0.3606,  0.2368, -0.2214,  0.3257,  0.1715,  0.2589, -0.0556, -0.2608],\n",
       "          [-0.0575, -0.1305, -0.2573,  0.0616, -0.2374, -0.3227,  0.0995,  0.1884],\n",
       "          [ 0.1872, -0.0738, -0.2209,  0.0159,  0.0161, -0.0212, -0.3472,  0.3726],\n",
       "          [ 0.1532, -0.0826, -0.3152,  0.0536, -0.1170,  0.3810, -0.1988, -0.2277],\n",
       "          [-0.1279, -0.3709,  0.3743,  0.2483, -0.3699, -0.1461, -0.1664,  0.0238],\n",
       "          [ 0.0700, -0.1749,  0.3812, -0.2667, -0.0385, -0.0740,  0.1206,  0.0325],\n",
       "          [ 0.0021,  0.3272, -0.3491, -0.1351, -0.3656, -0.2755,  0.3036, -0.1971],\n",
       "          [-0.3244,  0.3196, -0.2944,  0.2945,  0.1899, -0.1780, -0.1598, -0.0827]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.3492,  0.0369, -0.1783,  0.1847, -0.1419, -0.0618, -0.0611, -0.1825,\n",
       "           0.1819, -0.0324,  0.2494,  0.1070,  0.1889,  0.2590, -0.1178,  0.1928,\n",
       "           0.1880,  0.2950, -0.2567, -0.1162, -0.0218, -0.2309, -0.1459, -0.0124,\n",
       "          -0.3187, -0.0826, -0.2832,  0.2443, -0.0592,  0.1145,  0.3420,  0.1718],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0023,  0.2150,  0.1495,  0.1550,  0.3405,  0.0137, -0.1116,  0.1108,\n",
       "          -0.3001, -0.0405,  0.3059, -0.3468, -0.2727,  0.1015,  0.0449,  0.2054,\n",
       "           0.2261,  0.1650,  0.0369, -0.1309,  0.3153,  0.2108,  0.3179, -0.2459,\n",
       "           0.0882,  0.1747,  0.2407,  0.0020, -0.2463, -0.0717, -0.0988, -0.0799],\n",
       "         requires_grad=True)]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "3661cc14ec4e9e27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:51:46.217152Z",
     "start_time": "2025-12-12T00:51:46.213107Z"
    }
   },
   "source": [
    "epochs = 400\n",
    "# BCELogits with L2 reg\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model2.parameters(), lr=0.001, weight_decay=1e-4)\n"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "da38f55d3403291d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:51:49.166590Z",
     "start_time": "2025-12-12T00:51:46.217403Z"
    }
   },
   "source": [
    "annealer = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "for epoch in range(epochs):\n",
    "    pLTBatch, pRTBatch = generate_balanced_pairs(train_person_indices, n_train_pairs, personIDs)\n",
    "    leftTrainBatch = packPad(pairedNP, lengthsNP, pLTBatch).to(device)\n",
    "    rightTrainBatch = packPad(pairedNP, lengthsNP, pRTBatch).to(device)\n",
    "    yTrainBatch = (torch.tensor(personIDs[pLTBatch] == personIDs[pRTBatch])\n",
    "          .reshape((-1, 1))\n",
    "          .to(device, dtype=torch.float32))\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    for i in range(4):\n",
    "        optimizer.zero_grad()\n",
    "        outputBatch = model2(leftTrainBatch, rightTrainBatch)\n",
    "        lossBatch = criterion(outputBatch, yTrainBatch)\n",
    "\n",
    "        lossBatch.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss += lossBatch.item()\n",
    "    annealer.step()\n",
    "    epoch_loss /= 4\n",
    "\n",
    "    # average loss for the epoch\n",
    "    if epoch % 25 != 0:\n",
    "        print(f\"Epoch {epoch:3d} – loss: {epoch_loss:.4f} - fPC {((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean():.4f}, {((model2(leftTrain, rightTrain)>0)==(yTrain>0.5)).float().mean():.4f}\")\n",
    "    if epoch % 25 == 0:\n",
    "        output = model2(leftTrain, rightTrain)\n",
    "        loss = criterion(output, yTrain)\n",
    "        print(f\"Epoch {epoch:3d} – loss: {loss:.4f} - fPC {((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean():.4f}, {((model2(leftTrain, rightTrain)>0)==(yTrain>0.5)).float().mean():.4f}\")\n",
    "        if loss.item() < 0.59:\n",
    "            break\n",
    "output = model2(leftTrain, rightTrain)\n",
    "loss = criterion(output, yTrain)\n",
    "assert loss.item() <= 0.6 # if this assertion fails that means we got stuck and the model was unable to find the right strategy.\n",
    "model2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 – loss: 0.7142 - fPC 0.4921, 0.5000\n",
      "Epoch   1 – loss: 0.7140 - fPC 0.4921, 0.5000\n",
      "Epoch   2 – loss: 0.7125 - fPC 0.4921, 0.5000\n",
      "Epoch   3 – loss: 0.7103 - fPC 0.4921, 0.5000\n",
      "Epoch   4 – loss: 0.7090 - fPC 0.4921, 0.5000\n",
      "Epoch   5 – loss: 0.7079 - fPC 0.4921, 0.5000\n",
      "Epoch   6 – loss: 0.7067 - fPC 0.4921, 0.5000\n",
      "Epoch   7 – loss: 0.7057 - fPC 0.4921, 0.5000\n",
      "Epoch   8 – loss: 0.7048 - fPC 0.4921, 0.5000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[46]\u001B[39m\u001B[32m, line 16\u001B[39m\n\u001B[32m     13\u001B[39m outputBatch = model2(leftTrainBatch, rightTrainBatch)\n\u001B[32m     14\u001B[39m lossBatch = criterion(outputBatch, yTrainBatch)\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m \u001B[43mlossBatch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m optimizer.step()\n\u001B[32m     18\u001B[39m optimizer.zero_grad()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.13/site-packages/torch/_tensor.py:570\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    567\u001B[39m     \u001B[38;5;66;03m# All strings are unicode in Python 3.\u001B[39;00m\n\u001B[32m    568\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m torch._tensor_str._str(\u001B[38;5;28mself\u001B[39m, tensor_contents=tensor_contents)\n\u001B[32m--> \u001B[39m\u001B[32m570\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mbackward\u001B[39m(\n\u001B[32m    571\u001B[39m     \u001B[38;5;28mself\u001B[39m, gradient=\u001B[38;5;28;01mNone\u001B[39;00m, retain_graph=\u001B[38;5;28;01mNone\u001B[39;00m, create_graph=\u001B[38;5;28;01mFalse\u001B[39;00m, inputs=\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    572\u001B[39m ):\n\u001B[32m    573\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001B[39;00m\n\u001B[32m    574\u001B[39m \n\u001B[32m    575\u001B[39m \u001B[33;03m    The graph is differentiated using the chain rule. If the tensor is\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    613\u001B[39m \u001B[33;03m            used to compute the :attr:`tensors`. Defaults to ``None``.\u001B[39;00m\n\u001B[32m    614\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m    615\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a0efea46b74867b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if \"pretrainedModel\" in globals().keys():\n",
    "    model2 = pretrainedModel\n",
    "else:\n",
    "    pretrainedModel = model2\n"
   ],
   "id": "f2cfa20be5f55292",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=0.001, weight_decay=1e-3, momentum=0.9)"
   ],
   "id": "34d40cf616df5db7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "annealer = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)\n",
    "for epoch in range(500):\n",
    "    permute = np.random.permutation(train_person_indices.shape[0])[:8]\n",
    "    pLTBatch, pRTBatch = generate_balanced_pairs(train_person_indices[permute], n_train_pairs*4, personIDs)\n",
    "    leftTrainBatch = packPad(pairedNP, lengthsNP, pLTBatch).to(device)\n",
    "    rightTrainBatch = packPad(pairedNP, lengthsNP, pRTBatch).to(device)\n",
    "    yTrainBatch = (torch.tensor(personIDs[pLTBatch] == personIDs[pRTBatch])\n",
    "          .reshape((-1, 1))\n",
    "          .to(device, dtype=torch.float32))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    epoch_loss = 0.0\n",
    "    outputBatch = model2(leftTrainBatch, rightTrainBatch)\n",
    "    lossBatch = criterion(outputBatch, yTrainBatch)\n",
    "\n",
    "    lossBatch.backward()\n",
    "    optimizer.step()\n",
    "    annealer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss += lossBatch.item()\n",
    "\n",
    "    # average loss for the epoch\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch:3d} – loss: {epoch_loss:.4f} - fPC {((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean():.4f}, {((model2(leftTrain, rightTrain)>0)==(yTrain>0.5)).float().mean():.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Epoch {epoch:3d} – loss: {epoch_loss:.4f} - fPC {((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean():.4f}, {((model2(leftTrain, rightTrain)>0)==(yTrain>0.5)).float().mean():.4f}\")"
   ],
   "id": "508c60fce524d6fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = model2",
   "id": "3266c15fc9555c07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ckpt = {\n",
    "    'epoch'         : epoch,                     # current epoch number\n",
    "    'model_state'   : model.state_dict(),        # model parameters\n",
    "    'optimizer_state': optimizer.state_dict(),   # optimizer internals\n",
    "    'scheduler_state': annealer.state_dict() if annealer else None,\n",
    "}\n",
    "torch.save(ckpt, 'model_other.pt')\n",
    "torch.save(model.state_dict(), 'model_weights_other.pt')\n"
   ],
   "id": "bb5756b283949eec",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a2ffde47d0a4b526",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "def confusion_rates(yhat: torch.Tensor, y: torch.Tensor):\n",
    "    tp = (yhat == 1) & (y == 1)\n",
    "    tn = (yhat == 0) & (y == 0)\n",
    "    fp = (yhat == 1) & (y == 0)\n",
    "    fn = (yhat == 0) & (y == 1)\n",
    "\n",
    "    TP = int(tp.sum().item())\n",
    "    TN = int(tn.sum().item())\n",
    "    FP = int(fp.sum().item())\n",
    "    FN = int(fn.sum().item())\n",
    "\n",
    "    eps = 1e-12\n",
    "    TPR = TP / (TP + FN + eps)   # recall / sensitivity\n",
    "    TNR = TN / (TN + FP + eps)   # specificity\n",
    "    FPR = FP / (FP + TN + eps)   # 1 - specificity\n",
    "    FNR = FN / (FN + TP + eps)   # 1 - recall\n",
    "\n",
    "    return {\"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
    "            \"TPR\": TPR, \"TNR\": TNR, \"FPR\": FPR, \"FNR\": FNR}\n",
    "\n",
    "def metrics(model, leftTest, rightTest, yTest):\n",
    "    yhat = model(leftTest, rightTest) > 0\n",
    "    y = yTest\n",
    "    return confusion_rates(yhat, y)\n",
    "\n",
    "res = metrics(model2, leftTest, rightTest, yTest)\n",
    "\n",
    "print(f\"True Positive Rate (Recall) : {res['TPR']:.4f}; TP : {res['TP']}\")\n",
    "print(f\"True Negative Rate (Spec.)  : {res['TNR']:.4f}; TN : {res['TN']}\")\n",
    "print(f\"False Positive Rate         : {res['FPR']:.4f}; FP : {res['FP']}\")\n",
    "print(f\"False Negative Rate         : {res['FNR']:.4f}; FN : {res['FN']}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-12T00:58:25.808693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weights = torch.load('model_weights.pt', map_location=device)\n",
    "model_new = BigModel()          # the same class you used during training\n",
    "model_new.load_state_dict(weights)\n",
    "model_new.to(device)\n",
    "\n",
    "res = metrics(model_new, leftTest, rightTest, yTest)\n",
    "print(\"Testing:\")\n",
    "print(f\"True Positive Rate (Recall) : {res['TPR']:.4f}; TP : {res['TP']}\")\n",
    "print(f\"True Negative Rate (Spec.)  : {res['TNR']:.4f}; TN : {res['TN']}\")\n",
    "print(f\"False Positive Rate         : {res['FPR']:.4f}; FP : {res['FP']}\")\n",
    "print(f\"False Negative Rate         : {res['FNR']:.4f}; FN : {res['FN']}\")\n",
    "print()\n",
    "res = metrics(model_new, leftTrain, rightTrain, yTrain)\n",
    "print(\"Training:\")\n",
    "print(f\"True Positive Rate (Recall) : {res['TPR']:.4f}; TP : {res['TP']}\")\n",
    "print(f\"True Negative Rate (Spec.)  : {res['TNR']:.4f}; TN : {res['TN']}\")\n",
    "print(f\"False Positive Rate         : {res['FPR']:.4f}; FP : {res['FP']}\")\n",
    "print(f\"False Negative Rate         : {res['FNR']:.4f}; FN : {res['FN']}\")\n",
    "\n",
    "positive: np.ndarray = (nn.Sigmoid()(model_new(leftTest, rightTest) - yTest)).detach().numpy()[yTest == 1]\n",
    "negative: np.ndarray = (nn.Sigmoid()(model_new(leftTest, rightTest) - yTest)).detach().numpy()[yTest == 0]\n",
    "positive.resize(max(negative.size,positive.size))\n",
    "negative.resize(max(positive.size,negative.size))\n",
    "np.vstack((positive,negative),)\n",
    "positive,negative"
   ],
   "id": "eb4cceaaa64eed94",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/everettwilber/PyCharmMiscProject/.venv/lib/python3.13/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:\n",
      "True Positive Rate (Recall) : 0.0000; TP : 0\n",
      "True Negative Rate (Spec.)  : 1.0000; TN : 32\n",
      "False Positive Rate         : 0.0000; FP : 0\n",
      "False Negative Rate         : 1.0000; FN : 31\n",
      "\n",
      "Training:\n",
      "True Positive Rate (Recall) : 0.2991; TP : 32\n",
      "True Negative Rate (Spec.)  : 0.9252; TN : 99\n",
      "False Positive Rate         : 0.0748; FP : 8\n",
      "False Negative Rate         : 0.7009; FN : 75\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
