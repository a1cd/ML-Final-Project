{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ]
  },
  {
   "cell_type": "code",
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:21:45.802Z",
     "start_time": "2025-12-12T21:21:45.203308Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from numpy.random.mtrand import permutation"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:21:45.827470Z",
     "start_time": "2025-12-12T21:21:45.802423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(torch.backends.mps.is_available())\n",
    "device = torch.device(\"cpu\") # Defaults to CPU"
   ],
   "id": "2144e2a1fac24e8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:21:45.853312Z",
     "start_time": "2025-12-12T21:21:45.836670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Example: Move a tensor or model to the MPS device\n",
    "class TwoBranch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model = nn.LSTM(input_size=3, hidden_size=16, batch_first=False, dropout=0.2, num_layers=1).to(device)\n",
    "        self.left = model\n",
    "        self.right = model\n",
    "        self.combine = nn.Linear(32, 32).to(device)\n",
    "        nn.init.xavier_uniform_(model.weight_ih_l0)\n",
    "        nn.init.xavier_uniform_(model.weight_hh_l0)\n",
    "    def forward(self, x_left, x_right):\n",
    "        _, (l_h, _) = self.left(x_left)\n",
    "        _, (r_h, _) = self.right(x_right)\n",
    "\n",
    "        l = l_h[-1]  # last layer, shape: (batch, hidden_size)\n",
    "        r = r_h[-1]\n",
    "\n",
    "        cat = torch.cat([l, r], dim=-1)  # shape: (batch, 10)\n",
    "        return self.combine(cat)          # shape: (batch, 10) -> Linear(10,1) -> (batch,1)\n",
    "class BigModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.branch = TwoBranch()\n",
    "        self.rest = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x_left, x_right):\n",
    "        x = self.branch(x_left, x_right)\n",
    "        return self.rest(x)\n",
    "model2=BigModel().to(device)\n",
    "\n"
   ],
   "id": "740ed56613448ae6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/everettwilber/PyCharmMiscProject/.venv/lib/python3.13/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "2d151ea48ca597e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "ad47713dbc1ce9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:21:45.868015Z",
     "start_time": "2025-12-12T21:21:45.854470Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "batch = 32\n",
    "seq_len = 64\n",
    "\n",
    "x_left  = torch.randn(seq_len, batch, 3, device=device)\n",
    "x_right = torch.randn(seq_len, batch, 3, device=device)\n",
    "\n",
    "# labels depend on problem:\n",
    "y = torch.randn(batch, 1, device=device)  # regression\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbatch = 32\\nseq_len = 64\\n\\nx_left  = torch.randn(seq_len, batch, 3, device=device)\\nx_right = torch.randn(seq_len, batch, 3, device=device)\\n\\n# labels depend on problem:\\ny = torch.randn(batch, 1, device=device)  # regression\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "662ce026650504db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:21:45.977329Z",
     "start_time": "2025-12-12T21:21:45.869907Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "files = glob.glob(\"data/*.json\")\n",
    "people = []\n",
    "for file in files:\n",
    "    df = pd.read_json(file)\n",
    "    drawings = []\n",
    "    for drawing in df.values:\n",
    "        drawing = drawing[0]\n",
    "        allTriples = []\n",
    "        for stroke in drawing:\n",
    "            points = stroke[\"points\"]\n",
    "            triples = [(point[\"x\"], point[\"y\"], point[\"time\"]) for point in points]\n",
    "            allTriples.extend(triples)\n",
    "        drawings.append(allTriples)\n",
    "    people.append(drawings)\n",
    "\n",
    "\n",
    "data = people\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "7cf159954d81a8ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:21:46.005984Z",
     "start_time": "2025-12-12T21:21:45.984186Z"
    }
   },
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "out_path = Path(\"output/data.json\")\n",
    "\n",
    "out_path.write_text(json.dumps(data, indent=2))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983106"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "e54d062d01d46332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:21:46.043480Z",
     "start_time": "2025-12-12T21:21:46.027258Z"
    }
   },
   "source": [
    "out_path = Path(\"output/data.json\")\n",
    "loaded = json.load(out_path.open())"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "2cc0a90f82c0158e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:21:46.135932Z",
     "start_time": "2025-12-12T21:21:46.053192Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "training: list[list[list[tuple[int, int, int]]]] = loaded\n",
    "pairedDeep = [[torch.tensor(drawing, device=device) for drawing in drawings] for drawings in training]\n",
    "paired: list[torch.Tensor] = []\n",
    "personIDs: list[int] = []\n",
    "for personID, person in enumerate(pairedDeep):\n",
    "    person = [drawing[:-1]-drawing[1:] for drawing in person]\n",
    "    a = [personID] * len(person)\n",
    "    personIDs.extend(a)\n",
    "    paired.extend([((i[:, :] - i.min(dim=0, keepdim=True).values) / (\n",
    "    (i.max(dim=0, keepdim=True).values - i.min(dim=0, keepdim=True).values)))*2-0.5 for i in person])\n",
    "personIDs = np.array(personIDs)\n",
    "lengths = torch.tensor([len(s) for s in paired])\n",
    "\n",
    "\n",
    "def packPad(pairs: list[torch.Tensor], lengths: torch.Tensor, indeces):\n",
    "    padded = nn.utils.rnn.pad_sequence([pairs[i].to(device) for i in indeces], batch_first=True).to(device)\n",
    "    lengths = lengths[indeces]\n",
    "    packed = nn.utils.rnn.pack_padded_sequence(\n",
    "        padded,\n",
    "        lengths,\n",
    "        batch_first=True,\n",
    "        enforce_sorted=False\n",
    "    ).float().to(device)\n",
    "    return packed\n",
    "\n",
    "\n",
    "\n",
    "# Split at PERSON level to prevent any leakage\n",
    "n_people = len(pairedDeep)\n",
    "split_person_idx = int(n_people * 0.8)\n",
    "\n",
    "# Get all indices for train people and test people\n",
    "train_person_indices = []\n",
    "test_person_indices = []\n",
    "\n",
    "for person_id in range(n_people):\n",
    "    person_mask = personIDs == person_id\n",
    "    person_samples = np.where(person_mask)[0]\n",
    "\n",
    "    if person_id < split_person_idx:\n",
    "        train_person_indices.extend(person_samples)\n",
    "    else:\n",
    "        test_person_indices.extend(person_samples)\n",
    "\n",
    "train_person_indices = np.array(train_person_indices)\n",
    "test_person_indices = np.array(test_person_indices)\n",
    "\n",
    "print(f\"Training people: 0-{split_person_idx-1}\")\n",
    "print(f\"Test people: {split_person_idx}-{n_people-1}\")\n",
    "print(f\"Train samples: {len(train_person_indices)}\")\n",
    "print(f\"Test samples: {len(test_person_indices)}\")\n",
    "\n",
    "\n",
    "def generate_balanced_pairs(indices, n_pairs, personIDs):\n",
    "    \"\"\"Generate 50/50 same-person vs different-person pairs\"\"\"\n",
    "    left_indices = []\n",
    "    right_indices = []\n",
    "\n",
    "    n_same = n_pairs // 2\n",
    "    n_diff = n_pairs - n_same\n",
    "\n",
    "    # Same-person pairs\n",
    "    for _ in range(n_same):\n",
    "        idx = np.random.choice(indices)\n",
    "        person_id = personIDs[idx]\n",
    "        same_person_mask = personIDs[indices] == person_id\n",
    "        same_person_indices = indices[same_person_mask]\n",
    "\n",
    "        if len(same_person_indices) > 1:\n",
    "            pair = np.random.choice(same_person_indices, size=2, replace=False)\n",
    "            left_indices.append(pair[0])\n",
    "            right_indices.append(pair[1])\n",
    "        else:\n",
    "            left_indices.append(idx)\n",
    "            right_indices.append(idx)\n",
    "\n",
    "    # Different-person pairs\n",
    "    for _ in range(n_diff):\n",
    "        idx1 = np.random.choice(indices)\n",
    "        person1 = personIDs[idx1]\n",
    "        diff_person_mask = personIDs[indices] != person1\n",
    "        diff_person_indices = indices[diff_person_mask]\n",
    "\n",
    "        if len(diff_person_indices) > 0:\n",
    "            idx2 = np.random.choice(diff_person_indices)\n",
    "            left_indices.append(idx1)\n",
    "            right_indices.append(idx2)\n",
    "        else:\n",
    "            left_indices.append(idx1)\n",
    "            right_indices.append(np.random.choice(indices))\n",
    "\n",
    "    return np.array(left_indices), np.array(right_indices)\n",
    "\n",
    "\n",
    "# Generate balanced pairs\n",
    "n_train_pairs = len(train_person_indices)  # Reduce multiplier for stability\n",
    "n_test_pairs = len(test_person_indices)\n",
    "\n",
    "pLT, pRT = generate_balanced_pairs(train_person_indices, n_train_pairs, personIDs)\n",
    "pLTest, pRTest = generate_balanced_pairs(test_person_indices, n_test_pairs, personIDs)\n",
    "\n",
    "pairedNP = paired\n",
    "lengthsNP = lengths\n",
    "leftTrain = packPad(pairedNP, lengthsNP, pLT).to(device)\n",
    "rightTrain = packPad(pairedNP, lengthsNP, pRT).to(device)\n",
    "yTrain = (torch.tensor(personIDs[pLT] == personIDs[pRT])\n",
    "          .reshape((-1, 1))\n",
    "          .to(device, dtype=torch.float32))\n",
    "\n",
    "leftTest = packPad(pairedNP, lengthsNP, pLTest).to(device)\n",
    "rightTest = packPad(pairedNP, lengthsNP, pRTest).to(device)\n",
    "yTest = (torch.tensor(personIDs[pLTest] == personIDs[pRTest])\n",
    "         .reshape((-1, 1))\n",
    "         .to(device, dtype=torch.float32))\n",
    "\n",
    "print(f\"\\nTrain: {(yTrain == 1).sum().item() / len(yTrain) * 100:.1f}% same person\")\n",
    "print(f\"Test:  {(yTest == 1).sum().item() / len(yTest) * 100:.1f}% same person\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training people: 0-15\n",
      "Test people: 16-20\n",
      "Train samples: 214\n",
      "Test samples: 63\n",
      "\n",
      "Train: 50.0% same person\n",
      "Test:  49.2% same person\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "e7c980897c1921d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:49:33.557908Z",
     "start_time": "2025-12-12T21:49:33.512158Z"
    }
   },
   "source": "len(np.unique(personIDs[train_person_indices])), len(np.unique(personIDs[test_person_indices]))\n",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "40e3fc2b044139f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:21:46.185483Z",
     "start_time": "2025-12-12T21:21:46.154757Z"
    }
   },
   "source": "str(((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean().item())",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4920634925365448'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "459fc8e5ae926f03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:21:46.205017Z",
     "start_time": "2025-12-12T21:21:46.187480Z"
    }
   },
   "source": [
    "model2.branch.left.all_weights"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Parameter containing:\n",
       "  tensor([[-0.0638, -0.2254,  0.0629],\n",
       "          [ 0.2376,  0.0336,  0.0846],\n",
       "          [ 0.0508, -0.0449, -0.1388],\n",
       "          [ 0.1512,  0.0095,  0.2152],\n",
       "          [ 0.2858,  0.0678,  0.0285],\n",
       "          [-0.1612,  0.0790, -0.2730],\n",
       "          [ 0.0517, -0.2180,  0.1074],\n",
       "          [ 0.1704, -0.1956,  0.1989],\n",
       "          [-0.0285, -0.2683,  0.2919],\n",
       "          [ 0.1163,  0.1361,  0.0430],\n",
       "          [-0.1374, -0.1551,  0.0709],\n",
       "          [-0.0355, -0.0658, -0.2429],\n",
       "          [-0.2852,  0.0573,  0.1404],\n",
       "          [-0.2975, -0.0958,  0.1661],\n",
       "          [-0.0181,  0.0750, -0.0700],\n",
       "          [ 0.2024, -0.1251, -0.0781],\n",
       "          [-0.2292,  0.2341, -0.1329],\n",
       "          [-0.0795,  0.1985, -0.0054],\n",
       "          [-0.2805, -0.1088,  0.1123],\n",
       "          [-0.2612,  0.1200,  0.0562],\n",
       "          [-0.1628,  0.1457,  0.0859],\n",
       "          [-0.0462,  0.2351, -0.0880],\n",
       "          [ 0.0075,  0.1968, -0.0495],\n",
       "          [ 0.0902, -0.1011,  0.1015],\n",
       "          [-0.2144, -0.2722, -0.0633],\n",
       "          [-0.0339,  0.1168,  0.0058],\n",
       "          [ 0.1404,  0.2769,  0.0274],\n",
       "          [-0.1763,  0.1987, -0.2735],\n",
       "          [-0.0754,  0.2211,  0.2023],\n",
       "          [ 0.1247, -0.2170,  0.0427],\n",
       "          [-0.0139, -0.2246, -0.0660],\n",
       "          [ 0.1327,  0.0608,  0.0931],\n",
       "          [-0.2895, -0.0947, -0.2234],\n",
       "          [-0.2642,  0.2768,  0.2169],\n",
       "          [ 0.1591, -0.0192, -0.1960],\n",
       "          [ 0.0566,  0.2705,  0.1555],\n",
       "          [-0.0549,  0.1000, -0.1056],\n",
       "          [ 0.2483, -0.1532, -0.0645],\n",
       "          [ 0.0848,  0.0958, -0.1534],\n",
       "          [-0.0756,  0.0684,  0.2271],\n",
       "          [-0.2119, -0.2972,  0.0647],\n",
       "          [ 0.1293, -0.2275,  0.2066],\n",
       "          [-0.0748, -0.1611,  0.2587],\n",
       "          [-0.0538,  0.1642, -0.1469],\n",
       "          [-0.2625, -0.2007, -0.0899],\n",
       "          [-0.0470, -0.0263,  0.1641],\n",
       "          [ 0.0963,  0.0034, -0.1050],\n",
       "          [ 0.2699,  0.2459, -0.1685],\n",
       "          [ 0.2802,  0.1676,  0.2558],\n",
       "          [-0.0472, -0.1160, -0.1582],\n",
       "          [-0.0913,  0.0468,  0.2956],\n",
       "          [-0.0196,  0.0817,  0.0450],\n",
       "          [ 0.1716, -0.0628,  0.2897],\n",
       "          [ 0.1595,  0.1545,  0.1099],\n",
       "          [-0.2581, -0.2277, -0.0321],\n",
       "          [-0.1030, -0.0938,  0.0585],\n",
       "          [ 0.1501,  0.2168, -0.1586],\n",
       "          [-0.0306, -0.0823,  0.0978],\n",
       "          [ 0.2752,  0.0445, -0.1867],\n",
       "          [ 0.0875, -0.0718,  0.1334],\n",
       "          [-0.0357,  0.1602, -0.1293],\n",
       "          [-0.2674, -0.2595,  0.1309],\n",
       "          [ 0.1519,  0.2550,  0.2615],\n",
       "          [ 0.0665, -0.0492, -0.0982]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1954, -0.1686,  0.1853,  ...,  0.1641, -0.2116, -0.0059],\n",
       "          [-0.1671, -0.2213, -0.2485,  ..., -0.1651, -0.1078,  0.1173],\n",
       "          [ 0.0732,  0.2601, -0.0246,  ...,  0.1844,  0.1064, -0.0821],\n",
       "          ...,\n",
       "          [-0.2623,  0.0529,  0.1767,  ..., -0.1241, -0.2271,  0.0696],\n",
       "          [-0.2476, -0.0573,  0.1994,  ...,  0.0715, -0.2424, -0.0556],\n",
       "          [-0.1313, -0.2524, -0.2607,  ...,  0.1387, -0.0307,  0.2079]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0779, -0.0340, -0.1094,  0.1895, -0.1924,  0.0787, -0.0916, -0.0371,\n",
       "           0.1359,  0.1425, -0.1095,  0.2106, -0.1177,  0.1616,  0.1086, -0.2213,\n",
       "           0.2023,  0.2075,  0.1694, -0.0896, -0.1124, -0.1774, -0.0381, -0.2178,\n",
       "          -0.1079,  0.0525,  0.0636,  0.1806, -0.1745,  0.2303,  0.2104,  0.0345,\n",
       "           0.0098,  0.0399, -0.0921,  0.1428, -0.1348,  0.0385, -0.0106,  0.1987,\n",
       "          -0.0612,  0.2380, -0.1110,  0.0048, -0.2060,  0.1629,  0.1479,  0.0087,\n",
       "           0.1266, -0.1131, -0.1726,  0.0091, -0.2234, -0.1132,  0.1015, -0.1315,\n",
       "           0.1658, -0.0849, -0.1687, -0.0544,  0.2099, -0.2250, -0.0531,  0.0149],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.2000, -0.0694, -0.0072,  0.1891, -0.2126, -0.1694,  0.0796,  0.0925,\n",
       "          -0.1988, -0.1526,  0.1500,  0.1050,  0.1135, -0.1420,  0.1952, -0.2174,\n",
       "          -0.0130, -0.2147,  0.1065, -0.2215, -0.1085,  0.0990,  0.2389, -0.2325,\n",
       "           0.1169,  0.1580,  0.2330, -0.1889,  0.1059,  0.0444, -0.1144, -0.0456,\n",
       "           0.0689, -0.1677, -0.1908, -0.2435, -0.0458,  0.1369, -0.0137, -0.1797,\n",
       "          -0.1662,  0.0530, -0.1485, -0.1266, -0.1999, -0.1880,  0.1035,  0.0689,\n",
       "          -0.1680,  0.2247,  0.0672, -0.2432, -0.1532, -0.0494,  0.1652, -0.1780,\n",
       "           0.0778,  0.0221, -0.0050,  0.1226, -0.0184,  0.1267,  0.0394,  0.2058],\n",
       "         requires_grad=True)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "3661cc14ec4e9e27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:21:46.658754Z",
     "start_time": "2025-12-12T21:21:46.206048Z"
    }
   },
   "source": [
    "epochs = 400\n",
    "# BCELogits with L2 reg\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model2.parameters(), lr=0.001, weight_decay=1e-5)\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "da38f55d3403291d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:22:04.270138Z",
     "start_time": "2025-12-12T21:21:46.659224Z"
    }
   },
   "source": [
    "annealer = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "for epoch in range(epochs):\n",
    "    pLTBatch, pRTBatch = generate_balanced_pairs(train_person_indices, n_train_pairs, personIDs)\n",
    "    leftTrainBatch = packPad(pairedNP, lengthsNP, pLTBatch).to(device)\n",
    "    rightTrainBatch = packPad(pairedNP, lengthsNP, pRTBatch).to(device)\n",
    "    yTrainBatch = (torch.tensor(personIDs[pLTBatch] == personIDs[pRTBatch])\n",
    "          .reshape((-1, 1))\n",
    "          .to(device, dtype=torch.float32))\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    for i in range(4):\n",
    "        optimizer.zero_grad()\n",
    "        outputBatch = model2(leftTrainBatch, rightTrainBatch)\n",
    "        lossBatch = criterion(outputBatch, yTrainBatch)\n",
    "\n",
    "        lossBatch.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss += lossBatch.item()\n",
    "    annealer.step()\n",
    "    epoch_loss /= 4\n",
    "\n",
    "    # average loss for the epoch\n",
    "    if epoch % 25 != 0 and epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch:3d} – loss: {epoch_loss:.4f} - fPC {((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean():.4f}, {((model2(leftTrain, rightTrain)>0)==(yTrain>0.5)).float().mean():.4f}\")\n",
    "    if epoch % 25 == 0:\n",
    "        output = model2(leftTrain, rightTrain)\n",
    "        loss = criterion(output, yTrain)\n",
    "        print(f\"Epoch {epoch:3d} – loss: {loss:.4f} - fPC {((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean():.4f}, {((model2(leftTrain, rightTrain)>0)==(yTrain>0.5)).float().mean():.4f}\")\n",
    "        if loss.item() < 0.59:\n",
    "            break\n",
    "output = model2(leftTrain, rightTrain)\n",
    "loss = criterion(output, yTrain)\n",
    "assert loss.item() <= 0.6 # if this assertion fails that means we got stuck and the model was unable to find the right strategy.\n",
    "model2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 – loss: 0.6932 - fPC 0.5079, 0.5000\n",
      "Epoch   5 – loss: 0.6925 - fPC 0.4444, 0.5234\n",
      "Epoch  10 – loss: 0.6926 - fPC 0.4603, 0.5093\n",
      "Epoch  15 – loss: 0.6897 - fPC 0.4921, 0.5187\n",
      "Epoch  20 – loss: 0.6842 - fPC 0.7143, 0.5514\n",
      "Epoch  25 – loss: 0.6745 - fPC 0.7619, 0.5794\n",
      "Epoch  30 – loss: 0.6452 - fPC 0.8254, 0.6449\n",
      "Epoch  35 – loss: 0.6183 - fPC 0.6667, 0.6168\n",
      "Epoch  40 – loss: 0.5916 - fPC 0.6508, 0.6822\n",
      "Epoch  45 – loss: 0.4863 - fPC 0.7778, 0.7664\n",
      "Epoch  50 – loss: 0.5064 - fPC 0.8730, 0.7243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BigModel(\n",
       "  (branch): TwoBranch(\n",
       "    (left): LSTM(3, 16, dropout=0.2)\n",
       "    (right): LSTM(3, 16, dropout=0.2)\n",
       "    (combine): Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (rest): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:22:04.385237Z",
     "start_time": "2025-12-12T21:22:04.317957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = model2(leftTrain, rightTrain)\n",
    "loss = criterion(output, yTrain)\n",
    "print(f\"Epoch {epoch:3d} – loss: {loss:.4f} - fPC {((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean():.4f}, {((model2(leftTrain, rightTrain)>0)==(yTrain>0.5)).float().mean():.4f}\")"
   ],
   "id": "a0efea46b74867b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  50 – loss: 0.5064 - fPC 0.8730, 0.7243\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:22:04.390345Z",
     "start_time": "2025-12-12T21:22:04.386258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# if \"pretrainedModel\" in globals().keys():\n",
    "#     model2 = pretrainedModel\n",
    "# else:\n",
    "#     pretrainedModel = model2\n"
   ],
   "id": "f2cfa20be5f55292",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:22:04.394719Z",
     "start_time": "2025-12-12T21:22:04.390683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=0.0001, weight_decay=1e-4, momentum=0.9)"
   ],
   "id": "34d40cf616df5db7",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:22:04.398872Z",
     "start_time": "2025-12-12T21:22:04.395094Z"
    }
   },
   "cell_type": "code",
   "source": "annealer = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)",
   "id": "508c60fce524d6fb",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:25:23.596895Z",
     "start_time": "2025-12-12T21:22:25.682418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(500-170):\n",
    "    permute = np.random.permutation(train_person_indices.shape[0])[:8]\n",
    "    pLTBatch, pRTBatch = generate_balanced_pairs(train_person_indices[permute], n_train_pairs*8, personIDs)\n",
    "    leftTrainBatch = packPad(pairedNP, lengthsNP, pLTBatch).to(device)\n",
    "    rightTrainBatch = packPad(pairedNP, lengthsNP, pRTBatch).to(device)\n",
    "    yTrainBatch = (torch.tensor(personIDs[pLTBatch] == personIDs[pRTBatch])\n",
    "          .reshape((-1, 1))\n",
    "          .to(device, dtype=torch.float32))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    epoch_loss = 0.0\n",
    "    outputBatch = model2(leftTrainBatch, rightTrainBatch)\n",
    "    lossBatch = criterion(outputBatch, yTrainBatch)\n",
    "\n",
    "    lossBatch.backward()\n",
    "    optimizer.step()\n",
    "    annealer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss += lossBatch.item()\n",
    "\n",
    "    # average loss for the epoch\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch:3d} – loss: {epoch_loss:.4f} - fPC {((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean():.4f}, {((model2(leftTrain, rightTrain)>0)==(yTrain>0.5)).float().mean():.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Epoch {epoch:3d} – loss: {epoch_loss:.4f} - fPC {((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean():.4f}, {((model2(leftTrain, rightTrain)>0)==(yTrain>0.5)).float().mean():.4f}\")"
   ],
   "id": "833fbbce1b4e1feb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 – loss: 0.5225 - fPC 0.8730, 0.7430\n",
      "Epoch  10 – loss: 0.3658 - fPC 0.8730, 0.7430\n",
      "Epoch  20 – loss: 0.3665 - fPC 0.8730, 0.7430\n",
      "Epoch  30 – loss: 0.4738 - fPC 0.8730, 0.7477\n",
      "Epoch  40 – loss: 0.4321 - fPC 0.8730, 0.7523\n",
      "Epoch  50 – loss: 0.3906 - fPC 0.8730, 0.7523\n",
      "Epoch  60 – loss: 0.3546 - fPC 0.8730, 0.7570\n",
      "Epoch  70 – loss: 0.3546 - fPC 0.8730, 0.7664\n",
      "Epoch  80 – loss: 0.3582 - fPC 0.8571, 0.7710\n",
      "Epoch  90 – loss: 0.3613 - fPC 0.8571, 0.7710\n",
      "Epoch 100 – loss: 0.6325 - fPC 0.8571, 0.7710\n",
      "Epoch 110 – loss: 0.3346 - fPC 0.8571, 0.7710\n",
      "Epoch 120 – loss: 0.3881 - fPC 0.8571, 0.7710\n",
      "Epoch 130 – loss: 0.4077 - fPC 0.8571, 0.7710\n",
      "Epoch 140 – loss: 0.3540 - fPC 0.8571, 0.7710\n",
      "Epoch 150 – loss: 0.2632 - fPC 0.8571, 0.7757\n",
      "Epoch 160 – loss: 0.2901 - fPC 0.8571, 0.7757\n",
      "Epoch 170 – loss: 0.3505 - fPC 0.8571, 0.7757\n",
      "Epoch 180 – loss: 0.4576 - fPC 0.8571, 0.7757\n",
      "Epoch 190 – loss: 0.4915 - fPC 0.8571, 0.7757\n",
      "Epoch 200 – loss: 0.5994 - fPC 0.8571, 0.7757\n",
      "Epoch 210 – loss: 0.2842 - fPC 0.8571, 0.7757\n",
      "Epoch 220 – loss: 0.3337 - fPC 0.8571, 0.7757\n",
      "Epoch 230 – loss: 0.3486 - fPC 0.8571, 0.7757\n",
      "Epoch 240 – loss: 0.3995 - fPC 0.8571, 0.7710\n",
      "Epoch 250 – loss: 0.3669 - fPC 0.8571, 0.7710\n",
      "Epoch 260 – loss: 0.3375 - fPC 0.8730, 0.7664\n",
      "Epoch 270 – loss: 0.4424 - fPC 0.8730, 0.7664\n",
      "Epoch 280 – loss: 0.5068 - fPC 0.8730, 0.7664\n",
      "Epoch 290 – loss: 0.4703 - fPC 0.8730, 0.7664\n",
      "Epoch 300 – loss: 0.3321 - fPC 0.8730, 0.7664\n",
      "Epoch 310 – loss: 0.4233 - fPC 0.8730, 0.7664\n",
      "Epoch 320 – loss: 0.3869 - fPC 0.8730, 0.7664\n",
      "Epoch 329 – loss: 0.4175 - fPC 0.8730, 0.7664\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:29:03.042496Z",
     "start_time": "2025-12-12T21:29:03.033359Z"
    }
   },
   "cell_type": "code",
   "source": "model = model2",
   "id": "3266c15fc9555c07",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model2 = model",
   "id": "6246853175703797",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:29:03.954255Z",
     "start_time": "2025-12-12T21:29:03.943910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ckpt = {\n",
    "    'epoch'         : epoch,                     # current epoch number\n",
    "    'model_state'   : model.state_dict(),        # model parameters\n",
    "    'optimizer_state': optimizer.state_dict(),   # optimizer internals\n",
    "    'scheduler_state': annealer.state_dict() if annealer else None,\n",
    "}\n",
    "torch.save(ckpt, 'bad.pt')\n",
    "torch.save(model.state_dict(), 'bad.pt')\n"
   ],
   "id": "bb5756b283949eec",
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "a2ffde47d0a4b526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:29:07.245332Z",
     "start_time": "2025-12-12T21:29:07.202087Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "def confusion_rates(yhat: torch.Tensor, y: torch.Tensor):\n",
    "    tp = (yhat == 1) & (y == 1)\n",
    "    tn = (yhat == 0) & (y == 0)\n",
    "    fp = (yhat == 1) & (y == 0)\n",
    "    fn = (yhat == 0) & (y == 1)\n",
    "\n",
    "    TP = int(tp.sum().item())\n",
    "    TN = int(tn.sum().item())\n",
    "    FP = int(fp.sum().item())\n",
    "    FN = int(fn.sum().item())\n",
    "\n",
    "    eps = 1e-12\n",
    "    TPR = TP / (TP + FN + eps)   # recall / sensitivity\n",
    "    TNR = TN / (TN + FP + eps)   # specificity\n",
    "    FPR = FP / (FP + TN + eps)   # 1 - specificity\n",
    "    FNR = FN / (FN + TP + eps)   # 1 - recall\n",
    "\n",
    "    return {\"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
    "            \"TPR\": TPR, \"TNR\": TNR, \"FPR\": FPR, \"FNR\": FNR}\n",
    "\n",
    "def metrics(model, leftTest, rightTest, yTest):\n",
    "    yhat = model(leftTest, rightTest) > 0\n",
    "    y = yTest\n",
    "    return confusion_rates(yhat, y)\n",
    "\n",
    "res = metrics(model2, leftTest, rightTest, yTest)\n",
    "\n",
    "print(f\"True Positive Rate (Recall) : {res['TPR']:.4f}; TP : {res['TP']}\")\n",
    "print(f\"True Negative Rate (Spec.)  : {res['TNR']:.4f}; TN : {res['TN']}\")\n",
    "print(f\"False Positive Rate         : {res['FPR']:.4f}; FP : {res['FP']}\")\n",
    "print(f\"False Negative Rate         : {res['FNR']:.4f}; FN : {res['FN']}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate (Recall) : 0.9032; TP : 28\n",
      "True Negative Rate (Spec.)  : 0.8437; TN : 27\n",
      "False Positive Rate         : 0.1562; FP : 5\n",
      "False Negative Rate         : 0.0968; FN : 3\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:34:36.363948Z",
     "start_time": "2025-12-12T21:34:36.285744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cpu\") # Defaults to CPU\n",
    "\n",
    "# Example: Move a tensor or model to the MPS device\n",
    "class TwoBranchFinal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model = nn.LSTM(input_size=3, hidden_size=16, batch_first=False, num_layers=1).to(device)\n",
    "        self.left = model\n",
    "        self.right = model\n",
    "        self.combine = nn.Linear(32, 32).to(device)\n",
    "        nn.init.xavier_uniform_(model.weight_ih_l0)\n",
    "        nn.init.xavier_uniform_(model.weight_hh_l0)\n",
    "    def forward(self, x_left, x_right):\n",
    "        _, (l_h, _) = self.left(x_left)\n",
    "        _, (r_h, _) = self.right(x_right)\n",
    "\n",
    "        l = l_h[-1]  # last layer, shape: (batch, hidden_size)\n",
    "        r = r_h[-1]\n",
    "\n",
    "        cat = torch.cat([l, r], dim=-1)  # shape: (batch, 10)\n",
    "        return self.combine(cat)          # shape: (batch, 10) -> Linear(10,1) -> (batch,1)\n",
    "class BigModelProd(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.branch = TwoBranchFinal()\n",
    "        self.rest = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x_left, x_right):\n",
    "        x = self.branch(x_left, x_right)\n",
    "        return self.rest(x)\n",
    "\n",
    "weights = torch.load('model_weights_other.pt', map_location=device)\n",
    "model_new = BigModelProd()          # the same class you used during training\n",
    "model_new.load_state_dict(weights)\n",
    "model_new.to(device)\n",
    "\n",
    "res = metrics(model_new, leftTest, rightTest, yTest)\n",
    "print(\"Testing:\")\n",
    "print(f\"True Positive Rate (Recall) : {res['TPR']:.4f}; TP : {res['TP']}\")\n",
    "print(f\"True Negative Rate (Spec.)  : {res['TNR']:.4f}; TN : {res['TN']}\")\n",
    "print(f\"False Positive Rate         : {res['FPR']:.4f}; FP : {res['FP']}\")\n",
    "print(f\"False Negative Rate         : {res['FNR']:.4f}; FN : {res['FN']}\")\n",
    "print()\n",
    "res = metrics(model_new, leftTrain, rightTrain, yTrain)\n",
    "print(\"Training:\")\n",
    "print(f\"True Positive Rate (Recall) : {res['TPR']:.4f}; TP : {res['TP']}\")\n",
    "print(f\"True Negative Rate (Spec.)  : {res['TNR']:.4f}; TN : {res['TN']}\")\n",
    "print(f\"False Positive Rate         : {res['FPR']:.4f}; FP : {res['FP']}\")\n",
    "print(f\"False Negative Rate         : {res['FNR']:.4f}; FN : {res['FN']}\")\n",
    "\n",
    "positive: np.ndarray = (nn.Sigmoid()(model_new(leftTest, rightTest) - yTest)).detach().numpy()[yTest == 1]\n",
    "negative: np.ndarray = (nn.Sigmoid()(model_new(leftTest, rightTest) - yTest)).detach().numpy()[yTest == 0]\n",
    "positive.resize(max(negative.size,positive.size))\n",
    "negative.resize(max(positive.size,negative.size))\n",
    "np.vstack((positive,negative))\n",
    "positive,negative"
   ],
   "id": "eb4cceaaa64eed94",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:\n",
      "True Positive Rate (Recall) : 0.9032; TP : 28\n",
      "True Negative Rate (Spec.)  : 0.8437; TN : 27\n",
      "False Positive Rate         : 0.1562; FP : 5\n",
      "False Negative Rate         : 0.0968; FN : 3\n",
      "\n",
      "Training:\n",
      "True Positive Rate (Recall) : 0.8411; TP : 90\n",
      "True Negative Rate (Spec.)  : 0.6916; TN : 74\n",
      "False Positive Rate         : 0.3084; FP : 33\n",
      "False Negative Rate         : 0.1589; FN : 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.48004085, 0.5337593 , 0.14064959, 0.5476826 , 0.36310938,\n",
       "        0.58609   , 0.51609075, 0.49388075, 0.49752975, 0.14486243,\n",
       "        0.4368893 , 0.5609226 , 0.21539004, 0.5913554 , 0.5947775 ,\n",
       "        0.5718898 , 0.4359781 , 0.3527774 , 0.3677233 , 0.4473823 ,\n",
       "        0.5610101 , 0.5550844 , 0.49440593, 0.49419335, 0.49625412,\n",
       "        0.5657231 , 0.57466877, 0.43665236, 0.60352755, 0.5613196 ,\n",
       "        0.52599514, 0.        ], dtype=float32),\n",
       " array([0.1445959 , 0.3156685 , 0.04014008, 0.10604444, 0.1441207 ,\n",
       "        0.0355303 , 0.02916823, 0.09374581, 0.3203415 , 0.02792595,\n",
       "        0.3885638 , 0.05924111, 0.05008363, 0.01962832, 0.7284317 ,\n",
       "        0.18959895, 0.0685721 , 0.0461051 , 0.7114167 , 0.63278234,\n",
       "        0.12396618, 0.46992308, 0.20911328, 0.12874149, 0.03917939,\n",
       "        0.18748778, 0.40572485, 0.04698633, 0.6819311 , 0.36078992,\n",
       "        0.58779305, 0.18767975], dtype=float32))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "db714bd6f7bb41f5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
