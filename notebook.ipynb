{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ]
  },
  {
   "cell_type": "code",
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:48:29.791897Z",
     "start_time": "2025-12-12T01:48:29.778202Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from numpy.random.mtrand import permutation"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "id": "babb231646cfad15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:48:29.821722Z",
     "start_time": "2025-12-12T01:48:29.792431Z"
    }
   },
   "source": [
    "print(torch.backends.mps.is_available())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:48:29.844199Z",
     "start_time": "2025-12-12T01:48:29.822465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cpu\") # Defaults to CPU\n",
    "\n",
    "# Example: Move a tensor or model to the MPS device\n",
    "class TwoBranch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model = nn.LSTM(input_size=3, hidden_size=8, batch_first=False, dropout=0.2, num_layers=1).to(device)\n",
    "        self.left = model\n",
    "        self.right = model\n",
    "        self.combine = nn.Linear(16, 9).to(device)\n",
    "        nn.init.xavier_uniform_(model.weight_ih_l0)\n",
    "        nn.init.xavier_uniform_(model.weight_hh_l0)\n",
    "    def forward(self, x_left, x_right):\n",
    "        _, (l_h, _) = self.left(x_left)\n",
    "        _, (r_h, _) = self.right(x_right)\n",
    "\n",
    "        l = l_h[-1]  # last layer, shape: (batch, hidden_size)\n",
    "        r = r_h[-1]\n",
    "\n",
    "        cat = torch.cat([l, r], dim=-1)  # shape: (batch, 10)\n",
    "        return self.combine(cat)          # shape: (batch, 10) -> Linear(10,1) -> (batch,1)\n",
    "class BigModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.branch = TwoBranch()\n",
    "        self.rest = nn.Sequential(\n",
    "            nn.Linear(9, 9),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(9, 9),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(9, 1)\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x_left, x_right):\n",
    "        x = self.branch(x_left, x_right)\n",
    "        return self.rest(x)\n",
    "model2=BigModel().to(device)\n",
    "\n"
   ],
   "id": "2144e2a1fac24e8b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/everettwilber/PyCharmMiscProject/.venv/lib/python3.13/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "id": "2d151ea48ca597e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "ad47713dbc1ce9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:48:29.878201Z",
     "start_time": "2025-12-12T01:48:29.845464Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "batch = 32\n",
    "seq_len = 64\n",
    "\n",
    "x_left  = torch.randn(seq_len, batch, 3, device=device)\n",
    "x_right = torch.randn(seq_len, batch, 3, device=device)\n",
    "\n",
    "# labels depend on problem:\n",
    "y = torch.randn(batch, 1, device=device)  # regression\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbatch = 32\\nseq_len = 64\\n\\nx_left  = torch.randn(seq_len, batch, 3, device=device)\\nx_right = torch.randn(seq_len, batch, 3, device=device)\\n\\n# labels depend on problem:\\ny = torch.randn(batch, 1, device=device)  # regression\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "id": "662ce026650504db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:48:29.940903Z",
     "start_time": "2025-12-12T01:48:29.878748Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "files = glob.glob(\"data/*.json\")\n",
    "people = []\n",
    "for file in files:\n",
    "    df = pd.read_json(file)\n",
    "    drawings = []\n",
    "    for drawing in df.values:\n",
    "        drawing = drawing[0]\n",
    "        allTriples = []\n",
    "        for stroke in drawing:\n",
    "            points = stroke[\"points\"]\n",
    "            triples = [(point[\"x\"], point[\"y\"], point[\"time\"]) for point in points]\n",
    "            allTriples.extend(triples)\n",
    "        drawings.append(allTriples)\n",
    "    people.append(drawings)\n",
    "\n",
    "\n",
    "data = people\n"
   ],
   "outputs": [],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "id": "7cf159954d81a8ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:48:29.960337Z",
     "start_time": "2025-12-12T01:48:29.941586Z"
    }
   },
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "out_path = Path(\"output/data.json\")\n",
    "\n",
    "out_path.write_text(json.dumps(data, indent=2))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983106"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "id": "e54d062d01d46332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:48:29.969864Z",
     "start_time": "2025-12-12T01:48:29.960761Z"
    }
   },
   "source": [
    "out_path = Path(\"output/data.json\")\n",
    "loaded = json.load(out_path.open())"
   ],
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "id": "2cc0a90f82c0158e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:48:30.039282Z",
     "start_time": "2025-12-12T01:48:29.970152Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "training: list[list[list[tuple[int, int, int]]]] = loaded\n",
    "pairedDeep = [[torch.tensor(drawing, device=device) for drawing in drawings] for drawings in training]\n",
    "paired: list[torch.Tensor] = []\n",
    "personIDs: list[int] = []\n",
    "for personID, person in enumerate(pairedDeep):\n",
    "    person = [drawing[:-1]-drawing[1:] for drawing in person]\n",
    "    a = [personID] * len(person)\n",
    "    personIDs.extend(a)\n",
    "    paired.extend([((i[:, :] - i.min(dim=0, keepdim=True).values) / (\n",
    "    (i.max(dim=0, keepdim=True).values - i.min(dim=0, keepdim=True).values)))*2-0.5 for i in person])\n",
    "personIDs = np.array(personIDs)\n",
    "lengths = torch.tensor([len(s) for s in paired])\n",
    "\n",
    "\n",
    "def packPad(pairs: list[torch.Tensor], lengths: torch.Tensor, indeces):\n",
    "    padded = nn.utils.rnn.pad_sequence([pairs[i].to(device) for i in indeces], batch_first=True).to(device)\n",
    "    lengths = lengths[indeces]\n",
    "    packed = nn.utils.rnn.pack_padded_sequence(\n",
    "        padded,\n",
    "        lengths,\n",
    "        batch_first=True,\n",
    "        enforce_sorted=False\n",
    "    ).float().to(device)\n",
    "    return packed\n",
    "\n",
    "\n",
    "\n",
    "# Split at PERSON level to prevent any leakage\n",
    "n_people = len(pairedDeep)\n",
    "split_person_idx = int(n_people * 0.8)\n",
    "\n",
    "# Get all indices for train people and test people\n",
    "train_person_indices = []\n",
    "test_person_indices = []\n",
    "\n",
    "for person_id in range(n_people):\n",
    "    person_mask = personIDs == person_id\n",
    "    person_samples = np.where(person_mask)[0]\n",
    "\n",
    "    if person_id < split_person_idx:\n",
    "        train_person_indices.extend(person_samples)\n",
    "    else:\n",
    "        test_person_indices.extend(person_samples)\n",
    "\n",
    "train_person_indices = np.array(train_person_indices)\n",
    "test_person_indices = np.array(test_person_indices)\n",
    "\n",
    "print(f\"Training people: 0-{split_person_idx-1}\")\n",
    "print(f\"Test people: {split_person_idx}-{n_people-1}\")\n",
    "print(f\"Train samples: {len(train_person_indices)}\")\n",
    "print(f\"Test samples: {len(test_person_indices)}\")\n",
    "\n",
    "\n",
    "def generate_balanced_pairs(indices, n_pairs, personIDs):\n",
    "    \"\"\"Generate 50/50 same-person vs different-person pairs\"\"\"\n",
    "    left_indices = []\n",
    "    right_indices = []\n",
    "\n",
    "    n_same = n_pairs // 2\n",
    "    n_diff = n_pairs - n_same\n",
    "\n",
    "    # Same-person pairs\n",
    "    for _ in range(n_same):\n",
    "        idx = np.random.choice(indices)\n",
    "        person_id = personIDs[idx]\n",
    "        same_person_mask = personIDs[indices] == person_id\n",
    "        same_person_indices = indices[same_person_mask]\n",
    "\n",
    "        if len(same_person_indices) > 1:\n",
    "            pair = np.random.choice(same_person_indices, size=2, replace=False)\n",
    "            left_indices.append(pair[0])\n",
    "            right_indices.append(pair[1])\n",
    "        else:\n",
    "            left_indices.append(idx)\n",
    "            right_indices.append(idx)\n",
    "\n",
    "    # Different-person pairs\n",
    "    for _ in range(n_diff):\n",
    "        idx1 = np.random.choice(indices)\n",
    "        person1 = personIDs[idx1]\n",
    "        diff_person_mask = personIDs[indices] != person1\n",
    "        diff_person_indices = indices[diff_person_mask]\n",
    "\n",
    "        if len(diff_person_indices) > 0:\n",
    "            idx2 = np.random.choice(diff_person_indices)\n",
    "            left_indices.append(idx1)\n",
    "            right_indices.append(idx2)\n",
    "        else:\n",
    "            left_indices.append(idx1)\n",
    "            right_indices.append(np.random.choice(indices))\n",
    "\n",
    "    return np.array(left_indices), np.array(right_indices)\n",
    "\n",
    "\n",
    "# Generate balanced pairs\n",
    "n_train_pairs = len(train_person_indices)  # Reduce multiplier for stability\n",
    "n_test_pairs = len(test_person_indices)\n",
    "\n",
    "pLT, pRT = generate_balanced_pairs(train_person_indices, n_train_pairs, personIDs)\n",
    "pLTest, pRTest = generate_balanced_pairs(test_person_indices, n_test_pairs, personIDs)\n",
    "\n",
    "pairedNP = paired\n",
    "lengthsNP = lengths\n",
    "leftTrain = packPad(pairedNP, lengthsNP, pLT).to(device)\n",
    "rightTrain = packPad(pairedNP, lengthsNP, pRT).to(device)\n",
    "yTrain = (torch.tensor(personIDs[pLT] == personIDs[pRT])\n",
    "          .reshape((-1, 1))\n",
    "          .to(device, dtype=torch.float32))\n",
    "\n",
    "leftTest = packPad(pairedNP, lengthsNP, pLTest).to(device)\n",
    "rightTest = packPad(pairedNP, lengthsNP, pRTest).to(device)\n",
    "yTest = (torch.tensor(personIDs[pLTest] == personIDs[pRTest])\n",
    "         .reshape((-1, 1))\n",
    "         .to(device, dtype=torch.float32))\n",
    "\n",
    "print(f\"\\nTrain: {(yTrain == 1).sum().item() / len(yTrain) * 100:.1f}% same person\")\n",
    "print(f\"Test:  {(yTest == 1).sum().item() / len(yTest) * 100:.1f}% same person\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training people: 0-15\n",
      "Test people: 16-20\n",
      "Train samples: 214\n",
      "Test samples: 63\n",
      "\n",
      "Train: 50.0% same person\n",
      "Test:  49.2% same person\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "id": "e7c980897c1921d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:48:30.043388Z",
     "start_time": "2025-12-12T01:48:30.039747Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "id": "40e3fc2b044139f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:48:30.065913Z",
     "start_time": "2025-12-12T01:48:30.044010Z"
    }
   },
   "source": "str(((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean().item())",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4920634925365448'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "id": "459fc8e5ae926f03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:48:30.087196Z",
     "start_time": "2025-12-12T01:48:30.066393Z"
    }
   },
   "source": [
    "model2.branch.left.all_weights"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Parameter containing:\n",
       "  tensor([[-2.4465e-01,  2.7145e-01,  1.8613e-01],\n",
       "          [ 1.5868e-01, -9.3852e-02,  3.0997e-01],\n",
       "          [-3.2976e-01,  1.5481e-01, -4.0240e-01],\n",
       "          [ 2.6991e-02, -3.4887e-01,  3.0414e-01],\n",
       "          [ 5.2266e-02, -1.6494e-02, -1.3136e-01],\n",
       "          [-1.6683e-01,  3.1976e-01,  2.5325e-01],\n",
       "          [ 1.8633e-01,  2.3193e-01,  1.2269e-01],\n",
       "          [-3.8317e-01, -1.8812e-01, -1.5951e-01],\n",
       "          [ 1.6612e-01, -4.7830e-02,  2.2606e-04],\n",
       "          [ 3.5345e-01,  2.2609e-01, -1.2092e-01],\n",
       "          [ 2.5655e-01, -1.7458e-01,  3.8707e-01],\n",
       "          [ 1.1227e-01, -1.8624e-01, -2.3755e-01],\n",
       "          [ 3.4310e-01,  3.8119e-02, -4.9239e-02],\n",
       "          [-8.6556e-02,  3.6173e-01,  1.2781e-01],\n",
       "          [-2.5932e-01,  2.1361e-01,  3.6353e-01],\n",
       "          [ 1.1038e-01, -1.4720e-01,  3.5833e-01],\n",
       "          [ 3.2984e-01,  2.7034e-01,  3.6420e-01],\n",
       "          [ 3.2912e-03, -5.7101e-02, -2.5856e-01],\n",
       "          [-4.0496e-01, -3.8120e-01, -4.0681e-01],\n",
       "          [ 1.7521e-01, -1.5151e-01,  2.3855e-01],\n",
       "          [ 1.6565e-01, -3.7607e-01,  8.6034e-02],\n",
       "          [ 2.0146e-01,  6.3082e-02, -2.0054e-01],\n",
       "          [-7.8577e-02, -1.7563e-01,  2.6342e-01],\n",
       "          [ 1.7450e-01, -7.7021e-03, -1.6954e-01],\n",
       "          [ 2.5083e-01,  2.0779e-02,  1.5881e-01],\n",
       "          [ 1.6406e-01, -3.3517e-01,  2.6235e-02],\n",
       "          [-3.2783e-01,  3.9510e-02, -3.1002e-01],\n",
       "          [ 2.8899e-01,  3.3418e-01, -2.8655e-01],\n",
       "          [ 2.5843e-01, -3.3960e-01,  3.1064e-01],\n",
       "          [-2.0616e-02,  3.2541e-01,  4.1179e-01],\n",
       "          [-9.3591e-02,  4.1343e-01, -8.3212e-04],\n",
       "          [-2.6376e-01,  1.0966e-01,  3.8284e-01]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0445, -0.3530,  0.3336, -0.1373, -0.3154,  0.1990, -0.3124, -0.1339],\n",
       "          [-0.0302, -0.3552, -0.3013,  0.0334, -0.3796,  0.0096,  0.0052,  0.0630],\n",
       "          [-0.2003, -0.0665,  0.1571,  0.2590,  0.3149, -0.2398,  0.2338, -0.2486],\n",
       "          [ 0.1609, -0.3269, -0.2966,  0.0954,  0.0020, -0.3303,  0.2548,  0.2994],\n",
       "          [ 0.0479,  0.2138,  0.1975, -0.1416,  0.0494,  0.3222,  0.0017,  0.0061],\n",
       "          [-0.1363,  0.0226, -0.0400, -0.0544, -0.0819,  0.2627, -0.0941, -0.2496],\n",
       "          [-0.1234,  0.1669, -0.2739,  0.3098, -0.1775,  0.3114,  0.3660, -0.2566],\n",
       "          [-0.3865,  0.3294, -0.1637,  0.0612,  0.1938, -0.0675, -0.0121, -0.1293],\n",
       "          [-0.0220, -0.1285, -0.2900,  0.2319,  0.2287, -0.2661, -0.0504, -0.1562],\n",
       "          [-0.3618, -0.2950, -0.3189,  0.1629, -0.1437, -0.0925,  0.2481, -0.1200],\n",
       "          [-0.1317,  0.0560,  0.0129,  0.2296, -0.2932, -0.2189,  0.0222, -0.1804],\n",
       "          [-0.3235,  0.0610, -0.3110, -0.1384, -0.1057,  0.1301,  0.2027, -0.0404],\n",
       "          [ 0.2913,  0.3219, -0.0716,  0.2711,  0.2912, -0.2350,  0.0635,  0.2911],\n",
       "          [ 0.1052, -0.1916,  0.1320, -0.2922,  0.2853,  0.2263,  0.1160,  0.2695],\n",
       "          [ 0.0160, -0.2223, -0.1504, -0.1102, -0.2276, -0.0118, -0.1168, -0.0766],\n",
       "          [-0.0613, -0.1953,  0.3720,  0.3562,  0.3270, -0.0857,  0.2582, -0.1555],\n",
       "          [ 0.3638,  0.0239, -0.2459, -0.0013,  0.1404,  0.3552,  0.0286,  0.3412],\n",
       "          [ 0.2772, -0.0495, -0.0091, -0.0954, -0.0865, -0.2840,  0.1763,  0.1772],\n",
       "          [ 0.0894,  0.1640,  0.2922,  0.0896, -0.3608,  0.2849, -0.3362, -0.0132],\n",
       "          [-0.0573,  0.0377, -0.2038,  0.0549,  0.0372, -0.1016, -0.0818, -0.2138],\n",
       "          [-0.2129,  0.1646,  0.1139,  0.3233, -0.0293, -0.3742, -0.1267, -0.3365],\n",
       "          [-0.0317, -0.0761,  0.0768,  0.3790, -0.2446, -0.2850,  0.0544, -0.1280],\n",
       "          [ 0.1336,  0.1415,  0.1361,  0.2765, -0.1217,  0.2496,  0.0362, -0.1140],\n",
       "          [ 0.1165,  0.0015,  0.1488,  0.2637, -0.1721, -0.1387,  0.2894, -0.3380],\n",
       "          [-0.2546, -0.0178,  0.2147, -0.3764, -0.1092,  0.3206,  0.3230, -0.0547],\n",
       "          [-0.2323, -0.2252, -0.3840,  0.1899,  0.3025, -0.0495,  0.2484,  0.3531],\n",
       "          [ 0.2194,  0.3277, -0.2381,  0.2588,  0.3327, -0.0533,  0.1553, -0.3756],\n",
       "          [ 0.0240, -0.1917,  0.0059, -0.0569, -0.0260, -0.1940,  0.0586, -0.3614],\n",
       "          [-0.2522,  0.2450, -0.3751, -0.1785,  0.1419,  0.3331, -0.3136, -0.2285],\n",
       "          [-0.0349,  0.3846, -0.3073,  0.1908, -0.1383, -0.2794, -0.1925,  0.0227],\n",
       "          [-0.0987, -0.1976, -0.3407, -0.0078, -0.1375, -0.0935,  0.2738,  0.3818],\n",
       "          [-0.1897, -0.3622,  0.0020,  0.0847, -0.1461,  0.2804,  0.1122,  0.1846]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.3066, -0.2040,  0.0449,  0.2226,  0.0311, -0.1534, -0.0916,  0.2634,\n",
       "           0.2935,  0.1286, -0.2827, -0.2568,  0.0791,  0.1228,  0.3137,  0.3118,\n",
       "           0.2869,  0.0942, -0.0901, -0.2811,  0.2308, -0.2970, -0.1999, -0.2157,\n",
       "           0.1309, -0.0223,  0.1171,  0.1204,  0.0914,  0.0596, -0.2034,  0.1596],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1392,  0.3508, -0.0511,  0.2772,  0.2195, -0.0471, -0.1864, -0.0904,\n",
       "           0.2902,  0.1221, -0.2105,  0.1776,  0.2299, -0.1947,  0.2220,  0.3357,\n",
       "           0.2277,  0.1142,  0.2525,  0.0328,  0.0259,  0.0834,  0.0309,  0.1723,\n",
       "          -0.0553,  0.2570, -0.2123,  0.0377,  0.1361, -0.0213, -0.2668,  0.2006],\n",
       "         requires_grad=True)]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "id": "3661cc14ec4e9e27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:48:30.092807Z",
     "start_time": "2025-12-12T01:48:30.087842Z"
    }
   },
   "source": [
    "epochs = 400\n",
    "# BCELogits with L2 reg\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model2.parameters(), lr=0.001, weight_decay=1e-5)\n"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "id": "da38f55d3403291d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:48:31.243363Z",
     "start_time": "2025-12-12T01:48:30.093028Z"
    }
   },
   "source": [
    "annealer = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "for epoch in range(epochs):\n",
    "    pLTBatch, pRTBatch = generate_balanced_pairs(train_person_indices, n_train_pairs, personIDs)\n",
    "    leftTrainBatch = packPad(pairedNP, lengthsNP, pLTBatch).to(device)\n",
    "    rightTrainBatch = packPad(pairedNP, lengthsNP, pRTBatch).to(device)\n",
    "    yTrainBatch = (torch.tensor(personIDs[pLTBatch] == personIDs[pRTBatch])\n",
    "          .reshape((-1, 1))\n",
    "          .to(device, dtype=torch.float32))\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    for i in range(4):\n",
    "        optimizer.zero_grad()\n",
    "        outputBatch = model2(leftTrainBatch, rightTrainBatch)\n",
    "        lossBatch = criterion(outputBatch, yTrainBatch)\n",
    "\n",
    "        lossBatch.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss += lossBatch.item()\n",
    "    annealer.step()\n",
    "    epoch_loss /= 4\n",
    "\n",
    "    # average loss for the epoch\n",
    "    if epoch % 25 != 0 and epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch:3d} – loss: {epoch_loss:.4f} - fPC {((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean():.4f}, {((model2(leftTrain, rightTrain)>0)==(yTrain>0.5)).float().mean():.4f}\")\n",
    "    if epoch % 25 == 0:\n",
    "        output = model2(leftTrain, rightTrain)\n",
    "        loss = criterion(output, yTrain)\n",
    "        print(f\"Epoch {epoch:3d} – loss: {loss:.4f} - fPC {((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean():.4f}, {((model2(leftTrain, rightTrain)>0)==(yTrain>0.5)).float().mean():.4f}\")\n",
    "        if loss.item() < 0.59:\n",
    "            break\n",
    "output = model2(leftTrain, rightTrain)\n",
    "loss = criterion(output, yTrain)\n",
    "assert loss.item() <= 0.6 # if this assertion fails that means we got stuck and the model was unable to find the right strategy.\n",
    "model2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 – loss: 0.6960 - fPC 0.4921, 0.5000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[76]\u001B[39m\u001B[32m, line 16\u001B[39m\n\u001B[32m     13\u001B[39m outputBatch = model2(leftTrainBatch, rightTrainBatch)\n\u001B[32m     14\u001B[39m lossBatch = criterion(outputBatch, yTrainBatch)\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m \u001B[43mlossBatch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m optimizer.step()\n\u001B[32m     18\u001B[39m optimizer.zero_grad()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.13/site-packages/torch/_tensor.py:625\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    615\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    616\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    617\u001B[39m         Tensor.backward,\n\u001B[32m    618\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    623\u001B[39m         inputs=inputs,\n\u001B[32m    624\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m625\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    626\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    627\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    349\u001B[39m     retain_graph = create_graph\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    353\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m354\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    362\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    839\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    840\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m841\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    842\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    843\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    844\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    845\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "output = model2(leftTrain, rightTrain)\n",
    "loss = criterion(output, yTrain)\n",
    "print(f\"Epoch {epoch:3d} – loss: {loss:.4f} - fPC {((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean():.4f}, {((model2(leftTrain, rightTrain)>0)==(yTrain>0.5)).float().mean():.4f}\")"
   ],
   "id": "a0efea46b74867b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# if \"pretrainedModel\" in globals().keys():\n",
    "#     model2 = pretrainedModel\n",
    "# else:\n",
    "#     pretrainedModel = model2\n"
   ],
   "id": "f2cfa20be5f55292",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=0.0001, weight_decay=1e-4, momentum=0.9)"
   ],
   "id": "34d40cf616df5db7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "annealer = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)\n",
    "for epoch in range(500):\n",
    "    permute = np.random.permutation(train_person_indices.shape[0])[:8]\n",
    "    pLTBatch, pRTBatch = generate_balanced_pairs(train_person_indices[permute], n_train_pairs*8, personIDs)\n",
    "    leftTrainBatch = packPad(pairedNP, lengthsNP, pLTBatch).to(device)\n",
    "    rightTrainBatch = packPad(pairedNP, lengthsNP, pRTBatch).to(device)\n",
    "    yTrainBatch = (torch.tensor(personIDs[pLTBatch] == personIDs[pRTBatch])\n",
    "          .reshape((-1, 1))\n",
    "          .to(device, dtype=torch.float32))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    epoch_loss = 0.0\n",
    "    outputBatch = model2(leftTrainBatch, rightTrainBatch)\n",
    "    lossBatch = criterion(outputBatch, yTrainBatch)\n",
    "\n",
    "    lossBatch.backward()\n",
    "    optimizer.step()\n",
    "    annealer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss += lossBatch.item()\n",
    "\n",
    "    # average loss for the epoch\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch:3d} – loss: {epoch_loss:.4f} - fPC {((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean():.4f}, {((model2(leftTrain, rightTrain)>0)==(yTrain>0.5)).float().mean():.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Epoch {epoch:3d} – loss: {epoch_loss:.4f} - fPC {((model2(leftTest, rightTest)>0)==(yTest>0.5)).float().mean():.4f}, {((model2(leftTrain, rightTrain)>0)==(yTrain>0.5)).float().mean():.4f}\")"
   ],
   "id": "508c60fce524d6fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = model2",
   "id": "3266c15fc9555c07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ckpt = {\n",
    "    'epoch'         : epoch,                     # current epoch number\n",
    "    'model_state'   : model.state_dict(),        # model parameters\n",
    "    'optimizer_state': optimizer.state_dict(),   # optimizer internals\n",
    "    'scheduler_state': annealer.state_dict() if annealer else None,\n",
    "}\n",
    "torch.save(ckpt, 'model_other.pt')\n",
    "torch.save(model.state_dict(), 'model_weights_other.pt')\n"
   ],
   "id": "bb5756b283949eec",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a2ffde47d0a4b526",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "def confusion_rates(yhat: torch.Tensor, y: torch.Tensor):\n",
    "    tp = (yhat == 1) & (y == 1)\n",
    "    tn = (yhat == 0) & (y == 0)\n",
    "    fp = (yhat == 1) & (y == 0)\n",
    "    fn = (yhat == 0) & (y == 1)\n",
    "\n",
    "    TP = int(tp.sum().item())\n",
    "    TN = int(tn.sum().item())\n",
    "    FP = int(fp.sum().item())\n",
    "    FN = int(fn.sum().item())\n",
    "\n",
    "    eps = 1e-12\n",
    "    TPR = TP / (TP + FN + eps)   # recall / sensitivity\n",
    "    TNR = TN / (TN + FP + eps)   # specificity\n",
    "    FPR = FP / (FP + TN + eps)   # 1 - specificity\n",
    "    FNR = FN / (FN + TP + eps)   # 1 - recall\n",
    "\n",
    "    return {\"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
    "            \"TPR\": TPR, \"TNR\": TNR, \"FPR\": FPR, \"FNR\": FNR}\n",
    "\n",
    "def metrics(model, leftTest, rightTest, yTest):\n",
    "    yhat = model(leftTest, rightTest) > 0\n",
    "    y = yTest\n",
    "    return confusion_rates(yhat, y)\n",
    "\n",
    "res = metrics(model2, leftTest, rightTest, yTest)\n",
    "\n",
    "print(f\"True Positive Rate (Recall) : {res['TPR']:.4f}; TP : {res['TP']}\")\n",
    "print(f\"True Negative Rate (Spec.)  : {res['TNR']:.4f}; TN : {res['TN']}\")\n",
    "print(f\"False Positive Rate         : {res['FPR']:.4f}; FP : {res['FP']}\")\n",
    "print(f\"False Negative Rate         : {res['FNR']:.4f}; FN : {res['FN']}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cpu\") # Defaults to CPU\n",
    "\n",
    "# Example: Move a tensor or model to the MPS device\n",
    "class TwoBranchFinal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model = nn.LSTM(input_size=3, hidden_size=8, batch_first=False, num_layers=1).to(device)\n",
    "        self.left = model\n",
    "        self.right = model\n",
    "        self.combine = nn.Linear(16, 9).to(device)\n",
    "        nn.init.xavier_uniform_(model.weight_ih_l0)\n",
    "        nn.init.xavier_uniform_(model.weight_hh_l0)\n",
    "    def forward(self, x_left, x_right):\n",
    "        _, (l_h, _) = self.left(x_left)\n",
    "        _, (r_h, _) = self.right(x_right)\n",
    "\n",
    "        l = l_h[-1]  # last layer, shape: (batch, hidden_size)\n",
    "        r = r_h[-1]\n",
    "\n",
    "        cat = torch.cat([l, r], dim=-1)  # shape: (batch, 10)\n",
    "        return self.combine(cat)          # shape: (batch, 10) -> Linear(10,1) -> (batch,1)\n",
    "class BigModelProd(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.branch = TwoBranchFinal()\n",
    "        self.rest = nn.Sequential(\n",
    "            nn.Linear(9, 9),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(9, 9),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(9, 1)\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x_left, x_right):\n",
    "        x = self.branch(x_left, x_right)\n",
    "        return self.rest(x)\n",
    "\n",
    "weights = torch.load('model_weights.pt', map_location=device)\n",
    "model_new = BigModelProd()          # the same class you used during training\n",
    "model_new.load_state_dict(weights)\n",
    "model_new.to(device)\n",
    "\n",
    "res = metrics(model_new, leftTest, rightTest, yTest)\n",
    "print(\"Testing:\")\n",
    "print(f\"True Positive Rate (Recall) : {res['TPR']:.4f}; TP : {res['TP']}\")\n",
    "print(f\"True Negative Rate (Spec.)  : {res['TNR']:.4f}; TN : {res['TN']}\")\n",
    "print(f\"False Positive Rate         : {res['FPR']:.4f}; FP : {res['FP']}\")\n",
    "print(f\"False Negative Rate         : {res['FNR']:.4f}; FN : {res['FN']}\")\n",
    "print()\n",
    "res = metrics(model_new, leftTrain, rightTrain, yTrain)\n",
    "print(\"Training:\")\n",
    "print(f\"True Positive Rate (Recall) : {res['TPR']:.4f}; TP : {res['TP']}\")\n",
    "print(f\"True Negative Rate (Spec.)  : {res['TNR']:.4f}; TN : {res['TN']}\")\n",
    "print(f\"False Positive Rate         : {res['FPR']:.4f}; FP : {res['FP']}\")\n",
    "print(f\"False Negative Rate         : {res['FNR']:.4f}; FN : {res['FN']}\")\n",
    "\n",
    "positive: np.ndarray = (nn.Sigmoid()(model_new(leftTest, rightTest) - yTest)).detach().numpy()[yTest == 1]\n",
    "negative: np.ndarray = (nn.Sigmoid()(model_new(leftTest, rightTest) - yTest)).detach().numpy()[yTest == 0]\n",
    "positive.resize(max(negative.size,positive.size))\n",
    "negative.resize(max(positive.size,negative.size))\n",
    "np.vstack((positive,negative))\n",
    "positive,negative"
   ],
   "id": "eb4cceaaa64eed94",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
