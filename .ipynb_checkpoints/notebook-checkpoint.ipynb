{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:58:55.993991Z",
     "start_time": "2025-12-11T03:58:55.990157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:58:56.007184Z",
     "start_time": "2025-12-11T03:58:55.994277Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.backends.mps.is_available())",
   "id": "babb231646cfad15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:58:56.032319Z",
     "start_time": "2025-12-11T03:58:56.008473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") # Apple GPU\n",
    "    print(\"Using MPS device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\") # Defaults to CPU\n",
    "    print(\"MPS device not found, using CPU\")\n",
    "\n",
    "# Example: Move a tensor or model to the MPS device\n",
    "class TwoBranch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model = nn.LSTM(input_size=3, hidden_size=5, batch_first=False, num_layers=2)\n",
    "        self.left = model\n",
    "        self.right = model\n",
    "        self.combine = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x_left, x_right):\n",
    "        _, (l_h, _) = self.left(x_left)\n",
    "        _, (r_h, _) = self.right(x_right)\n",
    "\n",
    "        l = l_h[-1]  # last layer, shape: (batch, hidden_size)\n",
    "        r = r_h[-1]\n",
    "\n",
    "        cat = torch.cat([l, r], dim=-1)  # shape: (batch, 10)\n",
    "        return self.combine(cat)          # shape: (batch, 10) -> Linear(10,1) -> (batch,1)\n",
    "class BigModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.branch = TwoBranch()\n",
    "        self.rest = nn.Sequential(\n",
    "            nn.GELU(),\n",
    "            nn.Linear(10, 8),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x_left, x_right):\n",
    "        x = self.branch(x_left, x_right)\n",
    "        return self.rest(x)\n",
    "model2=BigModel()\n",
    "model2.to(device)\n",
    "\n"
   ],
   "id": "2144e2a1fac24e8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BigModel(\n",
       "  (branch): TwoBranch(\n",
       "    (left): LSTM(3, 5, num_layers=2)\n",
       "    (right): LSTM(3, 5, num_layers=2)\n",
       "    (combine): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       "  (rest): Sequential(\n",
       "    (0): GELU(approximate='none')\n",
       "    (1): Linear(in_features=10, out_features=8, bias=True)\n",
       "    (2): GELU(approximate='none')\n",
       "    (3): Linear(in_features=8, out_features=4, bias=True)\n",
       "    (4): GELU(approximate='none')\n",
       "    (5): Linear(in_features=4, out_features=1, bias=True)\n",
       "    (6): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "2d151ea48ca597e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:58:56.049939Z",
     "start_time": "2025-12-11T03:58:56.033833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "batch = 32\n",
    "seq_len = 64\n",
    "\n",
    "x_left  = torch.randn(seq_len, batch, 3, device=device)\n",
    "x_right = torch.randn(seq_len, batch, 3, device=device)\n",
    "\n",
    "# labels depend on problem:\n",
    "y = torch.randn(batch, 1, device=device)  # regression\n",
    "\"\"\""
   ],
   "id": "ad47713dbc1ce9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbatch = 32\\nseq_len = 64\\n\\nx_left  = torch.randn(seq_len, batch, 3, device=device)\\nx_right = torch.randn(seq_len, batch, 3, device=device)\\n\\n# labels depend on problem:\\ny = torch.randn(batch, 1, device=device)  # regression\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:58:56.084498Z",
     "start_time": "2025-12-11T03:58:56.050321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "files = glob.glob(\"data/*.json\")\n",
    "people = []\n",
    "for file in files:\n",
    "    df = pd.read_json(file)\n",
    "    drawings = []\n",
    "    for drawing in df.values:\n",
    "        points = drawing[0][0][\"points\"]\n",
    "        triples = [(point[\"x\"], point[\"y\"], point[\"time\"]) for point in points]\n",
    "        drawings.append(triples)\n",
    "    people.append(drawings)\n",
    "\n",
    "\n",
    "data = people\n"
   ],
   "id": "662ce026650504db",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:58:56.107630Z",
     "start_time": "2025-12-11T03:58:56.085069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "out_path = Path(\"output/data.json\")\n",
    "\n",
    "out_path.write_text(json.dumps(data, indent=2))"
   ],
   "id": "7cf159954d81a8ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485185"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:58:56.124724Z",
     "start_time": "2025-12-11T03:58:56.108082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_path = Path(\"output/data.json\")\n",
    "loaded = json.load(out_path.open())"
   ],
   "id": "e54d062d01d46332",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Looking at your code, I can see several issues with the train/test split creation:\n",
    "\n",
    "1. You're using `len(left)` but `left` is not defined - it should be `len(paired)`\n",
    "2. You're overwriting `leftTrain`, `rightTrain`, and `yTrain` instead of creating separate test variables\n",
    "3. The variable naming is inconsistent\n",
    "\n",
    "Here's the fixed code for your cell:\n",
    "\n"
   ],
   "id": "421c884230872855"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:58:56.228885Z",
     "start_time": "2025-12-11T03:58:56.125972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "training: list[list[list[tuple[int, int, int]]]] = loaded\n",
    "pairedDeep = [[torch.tensor(drawing, device=device) for drawing in drawings] for drawings in training]\n",
    "paired: list[torch.Tensor] = []\n",
    "personIDs: list[int] = []\n",
    "for personID, person in enumerate(pairedDeep):\n",
    "    person = [person[0][:-1]-person[0][1:] for drawing in person]\n",
    "    a = [personID] * len(person)\n",
    "    personIDs.extend(a)\n",
    "    paired.extend([(i[:, :] - i.min(dim=0, keepdim=True).values) / (\n",
    "    (i.max(dim=0, keepdim=True).values - i.min(dim=0, keepdim=True).values)) for i in person])\n",
    "personIDs = np.array(personIDs)\n",
    "lengths = torch.tensor([len(s) for s in paired])\n",
    "\n",
    "\n",
    "def packPad(pairs: list[torch.Tensor], lengths: torch.Tensor, indeces):\n",
    "    padded = nn.utils.rnn.pad_sequence([pairs[i] for i in indeces], batch_first=True)\n",
    "    padded.to(device)\n",
    "    lengths = lengths[indeces]\n",
    "    packed = nn.utils.rnn.pack_padded_sequence(\n",
    "        padded,\n",
    "        lengths,\n",
    "        batch_first=True,\n",
    "        enforce_sorted=False\n",
    "    ).float()\n",
    "    packed.to(device)\n",
    "    return packed\n",
    "\n",
    "\n",
    "# Split at the drawing level to prevent data leakage\n",
    "n_samples = len(paired)\n",
    "split_idx = int(n_samples * 0.8)\n",
    "\n",
    "# Create train/test indices without overlap\n",
    "indices = np.arange(n_samples)\n",
    "np.random.shuffle(indices)\n",
    "train_indices = indices[:split_idx]\n",
    "test_indices = indices[split_idx:]\n",
    "\n",
    "# Generate pairs only within each split\n",
    "def generate_pairs(indices, n_pairs):\n",
    "    left = np.random.choice(indices, size=n_pairs, replace=True)\n",
    "    right = np.random.choice(indices, size=n_pairs, replace=True)\n",
    "    return left, right\n",
    "\n",
    "def generate_balanced_pairs(indices, n_pairs, personIDs):\n",
    "    \"\"\"\n",
    "    Generate pairs with 50/50 split: same person vs different person.\n",
    "    Ensures balanced training data.\n",
    "    \"\"\"\n",
    "    left_indices = []\n",
    "    right_indices = []\n",
    "\n",
    "    n_same = n_pairs // 2\n",
    "    n_diff = n_pairs - n_same\n",
    "\n",
    "    # Generate same-person pairs\n",
    "    for _ in range(n_same):\n",
    "        # Pick a random sample\n",
    "        idx = np.random.choice(indices)\n",
    "        person_id = personIDs[idx]\n",
    "\n",
    "        # Find all samples from the same person\n",
    "        same_person_mask = personIDs[indices] == person_id\n",
    "        same_person_indices = indices[same_person_mask]\n",
    "\n",
    "        # Pick two different samples from same person (if available)\n",
    "        if len(same_person_indices) > 1:\n",
    "            pair = np.random.choice(same_person_indices, size=2, replace=False)\n",
    "            left_indices.append(pair[0])\n",
    "            right_indices.append(pair[1])\n",
    "        else:\n",
    "            # Fallback: just pick the same sample twice\n",
    "            left_indices.append(idx)\n",
    "            right_indices.append(idx)\n",
    "\n",
    "    # Generate different-person pairs\n",
    "    for _ in range(n_diff):\n",
    "        # Pick first sample\n",
    "        idx1 = np.random.choice(indices)\n",
    "        person1 = personIDs[idx1]\n",
    "\n",
    "        # Find all samples from different people\n",
    "        diff_person_mask = personIDs[indices] != person1\n",
    "        diff_person_indices = indices[diff_person_mask]\n",
    "\n",
    "        # Pick a sample from different person\n",
    "        if len(diff_person_indices) > 0:\n",
    "            idx2 = np.random.choice(diff_person_indices)\n",
    "            left_indices.append(idx1)\n",
    "            right_indices.append(idx2)\n",
    "        else:\n",
    "            # Fallback: pick any two random samples\n",
    "            left_indices.append(idx1)\n",
    "            right_indices.append(np.random.choice(indices))\n",
    "\n",
    "    return np.array(left_indices), np.array(right_indices)\n",
    "\n",
    "# Generate pairs for training and testing\n",
    "n_train_pairs = len(train_indices) * 10\n",
    "n_test_pairs = len(test_indices) * 10\n",
    "\n",
    "pLT, pRT = generate_balanced_pairs(train_indices, n_train_pairs, personIDs)\n",
    "pLTest, pRTest = generate_balanced_pairs(test_indices, n_test_pairs, personIDs)\n",
    "\n",
    "pairedNP = paired\n",
    "lengthsNP = lengths\n",
    "leftTrain = packPad(pairedNP, lengthsNP, pLT)\n",
    "rightTrain = packPad(pairedNP, lengthsNP, pRT)\n",
    "yTrain = (torch.tensor(personIDs[pLT] == personIDs[pRT])\n",
    "          .reshape((-1, 1))\n",
    "          .to(device, dtype=torch.float32))\n",
    "\n",
    "leftTest = packPad(pairedNP, lengthsNP, pLTest)\n",
    "rightTest = packPad(pairedNP, lengthsNP, pRTest)\n",
    "yTest = (torch.tensor(personIDs[pLTest] == personIDs[pRTest])\n",
    "         .reshape((-1, 1))\n",
    "         .to(device, dtype=torch.float32))\n"
   ],
   "id": "2cc0a90f82c0158e",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:58:56.232268Z",
     "start_time": "2025-12-11T03:58:56.229197Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e7c980897c1921d6",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:58:56.281608Z",
     "start_time": "2025-12-11T03:58:56.232557Z"
    }
   },
   "cell_type": "code",
   "source": "str((model2(leftTest, rightTest).round().int()==yTest.int()).float().mean().item())",
   "id": "40e3fc2b044139f8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:58:56.508245Z",
     "start_time": "2025-12-11T03:58:56.282559Z"
    }
   },
   "cell_type": "code",
   "source": "model2.branch.left.all_weights",
   "id": "459fc8e5ae926f03",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Parameter containing:\n",
       "  tensor([[-0.4208,  0.3523, -0.0064],\n",
       "          [ 0.0606,  0.4008,  0.1546],\n",
       "          [-0.0039,  0.2558, -0.0293],\n",
       "          [ 0.4243,  0.2529, -0.4364],\n",
       "          [ 0.0460,  0.0681,  0.2478],\n",
       "          [ 0.0605,  0.2850,  0.2364],\n",
       "          [-0.4232, -0.3012, -0.1687],\n",
       "          [-0.0105, -0.1516, -0.3528],\n",
       "          [ 0.4441,  0.3781,  0.3879],\n",
       "          [-0.2322, -0.2888, -0.1447],\n",
       "          [ 0.4440,  0.0854,  0.1620],\n",
       "          [ 0.1607,  0.1150, -0.2531],\n",
       "          [ 0.0231, -0.0087, -0.1566],\n",
       "          [ 0.0647, -0.1193,  0.3009],\n",
       "          [ 0.2165, -0.1639,  0.3672],\n",
       "          [ 0.1502,  0.3651,  0.2030],\n",
       "          [-0.2576, -0.0226, -0.1681],\n",
       "          [-0.2022,  0.2566,  0.0795],\n",
       "          [-0.1303, -0.2519,  0.0230],\n",
       "          [ 0.0075, -0.1162, -0.0221]], device='mps:0', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2630, -0.4313, -0.1915,  0.4331,  0.1209],\n",
       "          [-0.0962,  0.1676, -0.2052, -0.3323,  0.1755],\n",
       "          [ 0.1615, -0.0931,  0.3451, -0.0464,  0.0495],\n",
       "          [-0.4088,  0.4247, -0.2946,  0.2069, -0.2282],\n",
       "          [-0.0147, -0.0908, -0.0007, -0.1274,  0.1042],\n",
       "          [ 0.0462,  0.0975,  0.3858, -0.1124,  0.1286],\n",
       "          [ 0.1609, -0.4419, -0.3571,  0.1580,  0.1933],\n",
       "          [ 0.1993,  0.2662,  0.0774,  0.0706, -0.1719],\n",
       "          [-0.0993,  0.0645,  0.0994, -0.4038,  0.3577],\n",
       "          [-0.1189,  0.3695, -0.1314, -0.4108,  0.1237],\n",
       "          [ 0.4445, -0.1256,  0.0598,  0.2509, -0.3768],\n",
       "          [-0.4174,  0.0165, -0.2749, -0.2065, -0.1714],\n",
       "          [-0.3695, -0.1261,  0.3427, -0.1614, -0.3450],\n",
       "          [-0.1587,  0.0392,  0.3501, -0.0937, -0.1338],\n",
       "          [-0.0362, -0.1210,  0.4005,  0.2810,  0.3311],\n",
       "          [ 0.3415,  0.2923, -0.2003, -0.2510,  0.0798],\n",
       "          [ 0.0124,  0.2769, -0.2433,  0.4462, -0.2911],\n",
       "          [-0.1742, -0.3930, -0.0189, -0.0369,  0.3541],\n",
       "          [-0.3999,  0.2157,  0.2518, -0.3426, -0.3721],\n",
       "          [-0.2765,  0.3951,  0.4164, -0.4017, -0.4076]], device='mps:0',\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.3837, -0.2196,  0.2386,  0.1870, -0.1961, -0.0205,  0.2396, -0.0989,\n",
       "           0.3584,  0.4301, -0.1931,  0.2545,  0.0349,  0.1429, -0.3289,  0.0827,\n",
       "           0.0669, -0.2220, -0.3692,  0.2811], device='mps:0',\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1508,  0.3900,  0.2710,  0.0553,  0.2738, -0.3090, -0.2707,  0.2973,\n",
       "           0.1629,  0.1092,  0.4334, -0.0964, -0.1308,  0.2261,  0.2266,  0.3549,\n",
       "          -0.3062, -0.1962,  0.2440, -0.3188], device='mps:0',\n",
       "         requires_grad=True)],\n",
       " [Parameter containing:\n",
       "  tensor([[ 0.2456, -0.2400, -0.0102, -0.2886,  0.4391],\n",
       "          [-0.2113, -0.1896, -0.3364, -0.3710, -0.3484],\n",
       "          [-0.3497, -0.1762, -0.1612,  0.4444,  0.4315],\n",
       "          [-0.2173,  0.0486,  0.2951, -0.0779, -0.3591],\n",
       "          [ 0.0474,  0.1124,  0.2614,  0.1833,  0.1518],\n",
       "          [ 0.1720,  0.0663,  0.4360,  0.0479,  0.0167],\n",
       "          [-0.4227, -0.4047,  0.2840,  0.2422, -0.4171],\n",
       "          [-0.2104,  0.0554, -0.4193, -0.4114, -0.1872],\n",
       "          [-0.4225, -0.1047, -0.2848, -0.2461,  0.2066],\n",
       "          [-0.3970,  0.3459,  0.3772, -0.1011, -0.1076],\n",
       "          [ 0.0653, -0.1421, -0.3869, -0.3803, -0.4000],\n",
       "          [ 0.0614, -0.2925,  0.2551, -0.0482,  0.0513],\n",
       "          [ 0.0964, -0.0829, -0.0829,  0.2198,  0.2047],\n",
       "          [ 0.2491, -0.0564, -0.0121, -0.2535, -0.3664],\n",
       "          [-0.2606, -0.2659,  0.0702, -0.3415, -0.1738],\n",
       "          [ 0.3915,  0.3684,  0.4266,  0.1053,  0.4105],\n",
       "          [ 0.3521,  0.2292, -0.4401,  0.0655, -0.4423],\n",
       "          [-0.2113, -0.2248,  0.2323, -0.4009, -0.2801],\n",
       "          [ 0.1573,  0.2148,  0.2406, -0.3422, -0.0188],\n",
       "          [ 0.1523, -0.3640, -0.3474,  0.1717, -0.3255]], device='mps:0',\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2162, -0.2862,  0.3706,  0.2060,  0.1905],\n",
       "          [ 0.2496,  0.4292,  0.2095,  0.2446, -0.3871],\n",
       "          [-0.0756, -0.3354,  0.0110,  0.3051, -0.2141],\n",
       "          [-0.3650,  0.0174, -0.2618, -0.1057, -0.0183],\n",
       "          [-0.1577,  0.0989,  0.3460, -0.2186,  0.0999],\n",
       "          [ 0.1601,  0.4192,  0.0223, -0.0299,  0.0546],\n",
       "          [-0.3813, -0.2136,  0.0311,  0.2440,  0.1549],\n",
       "          [-0.0004,  0.1704, -0.1287, -0.1346,  0.1420],\n",
       "          [-0.4317,  0.4009, -0.3606, -0.0110, -0.1728],\n",
       "          [ 0.2495, -0.0139, -0.2068,  0.2688,  0.2905],\n",
       "          [-0.1752, -0.1992, -0.3716, -0.3208,  0.3888],\n",
       "          [ 0.1919, -0.2221,  0.2841, -0.4124, -0.3367],\n",
       "          [ 0.3117, -0.3016,  0.3299, -0.3095, -0.3385],\n",
       "          [ 0.1718,  0.2811,  0.0152, -0.1944, -0.0078],\n",
       "          [ 0.3119, -0.3090,  0.3990,  0.3477,  0.1741],\n",
       "          [-0.4375, -0.2892, -0.3673,  0.3729, -0.1555],\n",
       "          [ 0.3251, -0.3962,  0.0998, -0.1624,  0.4213],\n",
       "          [ 0.0127, -0.0268,  0.0768, -0.2529, -0.2240],\n",
       "          [-0.4035,  0.4423,  0.2957,  0.3829,  0.2121],\n",
       "          [ 0.1372,  0.0443, -0.1120,  0.2880,  0.1366]], device='mps:0',\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.2445,  0.0164, -0.3383, -0.3137, -0.2006,  0.4076,  0.1980,  0.0273,\n",
       "          -0.0795,  0.3002, -0.4183, -0.0428, -0.4225, -0.3879, -0.2619, -0.1132,\n",
       "           0.1422, -0.2120, -0.2228, -0.0528], device='mps:0',\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.4348, -0.3927, -0.4426,  0.1215,  0.2596, -0.1215,  0.3226,  0.0743,\n",
       "           0.2140, -0.1256, -0.0360, -0.1025,  0.3410, -0.3518,  0.2077,  0.1989,\n",
       "           0.1482, -0.1813, -0.3968,  0.3049], device='mps:0',\n",
       "         requires_grad=True)]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:58:56.524260Z",
     "start_time": "2025-12-11T03:58:56.516140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 1000\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(model2.parameters(), lr=0.01)\n",
    "annealer = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)"
   ],
   "id": "3661cc14ec4e9e27",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T04:01:07.226462Z",
     "start_time": "2025-12-11T03:58:56.524836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    epoch_loss = 0.0\n",
    "    output = model2(leftTrain, rightTrain)\n",
    "    loss = criterion(output, yTrain)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss += loss.item() * yTrain.size(0)\n",
    "\n",
    "    # average loss for the epoch\n",
    "    epoch_loss /= len(leftTrain)\n",
    "\n",
    "\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch:3d} – loss: {epoch_loss:.4f} - fPC {(model2(leftTest, rightTest).round().int()==yTest.int()).float().mean():.4f}, {(model2(leftTrain, rightTrain).round().int()==yTrain.int()).float().mean():.4f}\")\n",
    "\n",
    "model2\n"
   ],
   "id": "da38f55d3403291d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 – loss: 230.6944 - fPC 0.5000, 0.5000\n",
      "Epoch  10 – loss: 230.4707 - fPC 0.5000, 0.5000\n",
      "Epoch  20 – loss: 230.4708 - fPC 0.5000, 0.5000\n",
      "Epoch  30 – loss: 230.4690 - fPC 0.5000, 0.5000\n",
      "Epoch  40 – loss: 230.4555 - fPC 0.4324, 0.4451\n",
      "Epoch  50 – loss: 229.9066 - fPC 0.5824, 0.5842\n",
      "Epoch  60 – loss: 207.5352 - fPC 0.5824, 0.5293\n",
      "Epoch  70 – loss: 169.4490 - fPC 0.7559, 0.7850\n",
      "Epoch  80 – loss: 144.6667 - fPC 0.7559, 0.7850\n",
      "Epoch  90 – loss: 145.1729 - fPC 0.7618, 0.8165\n",
      "Epoch 100 – loss: 119.6527 - fPC 0.8676, 0.8586\n",
      "Epoch 110 – loss: 110.3188 - fPC 0.8676, 0.8805\n",
      "Epoch 120 – loss: 83.5900 - fPC 0.8941, 0.9180\n",
      "Epoch 130 – loss: 71.0848 - fPC 0.9059, 0.9308\n",
      "Epoch 140 – loss: 57.8794 - fPC 0.8471, 0.9180\n",
      "Epoch 150 – loss: 63.9318 - fPC 0.9941, 0.9872\n",
      "Epoch 160 – loss: 32.4070 - fPC 0.9529, 0.9639\n",
      "Epoch 170 – loss: 33.3122 - fPC 0.9618, 0.9541\n",
      "Epoch 180 – loss: 48.5456 - fPC 0.9353, 0.9519\n",
      "Epoch 190 – loss: 19.6245 - fPC 0.9765, 0.9797\n",
      "Epoch 200 – loss: 45.5875 - fPC 0.9618, 0.9677\n",
      "Epoch 210 – loss: 44.3539 - fPC 0.9647, 0.9789\n",
      "Epoch 220 – loss: 102.5070 - fPC 0.8441, 0.8782\n",
      "Epoch 230 – loss: 27.2128 - fPC 0.9676, 0.9511\n",
      "Epoch 240 – loss: 49.7826 - fPC 0.9735, 0.9812\n",
      "Epoch 250 – loss: 33.9305 - fPC 0.9382, 0.9504\n",
      "Epoch 260 – loss: 73.8307 - fPC 0.9118, 0.8925\n",
      "Epoch 270 – loss: 119.9690 - fPC 0.9471, 0.9579\n",
      "Epoch 280 – loss: 85.8601 - fPC 0.9647, 0.9571\n",
      "Epoch 290 – loss: 49.8386 - fPC 0.9971, 0.9925\n",
      "Epoch 300 – loss: 35.4610 - fPC 0.9706, 0.9887\n",
      "Epoch 310 – loss: 19.9779 - fPC 0.9647, 0.9699\n",
      "Epoch 320 – loss: 36.6889 - fPC 0.9735, 0.9782\n",
      "Epoch 330 – loss: 22.9660 - fPC 0.9618, 0.9669\n",
      "Epoch 340 – loss: 19.0115 - fPC 0.9676, 0.9774\n",
      "Epoch 350 – loss: 17.1661 - fPC 0.9912, 0.9880\n",
      "Epoch 360 – loss: 13.4948 - fPC 0.9853, 0.9925\n",
      "Epoch 370 – loss: 11.1892 - fPC 0.9765, 0.9865\n",
      "Epoch 380 – loss: 84.0712 - fPC 0.9912, 0.9489\n",
      "Epoch 390 – loss: 40.0804 - fPC 0.9941, 0.9857\n",
      "Epoch 400 – loss: 29.3080 - fPC 0.9971, 0.9624\n",
      "Epoch 410 – loss: 35.2934 - fPC 0.9971, 0.9850\n",
      "Epoch 420 – loss: 30.6722 - fPC 0.9853, 0.9797\n",
      "Epoch 430 – loss: 63.3378 - fPC 0.9971, 0.9925\n",
      "Epoch 440 – loss: 18.0765 - fPC 0.9853, 0.9865\n",
      "Epoch 450 – loss: 37.7240 - fPC 0.9971, 0.9925\n",
      "Epoch 460 – loss: 27.7954 - fPC 0.9971, 0.9925\n",
      "Epoch 470 – loss: 20.8620 - fPC 0.9794, 0.9789\n",
      "Epoch 480 – loss: 17.1017 - fPC 0.9912, 0.9880\n",
      "Epoch 490 – loss: 12.9333 - fPC 0.9971, 0.9925\n",
      "Epoch 500 – loss: 12.2854 - fPC 0.9971, 0.9925\n",
      "Epoch 510 – loss: 11.2240 - fPC 0.9971, 0.9925\n",
      "Epoch 520 – loss: 10.6924 - fPC 0.9971, 0.9925\n",
      "Epoch 530 – loss: 10.3200 - fPC 0.9971, 0.9925\n",
      "Epoch 540 – loss: 10.0865 - fPC 0.9971, 0.9925\n",
      "Epoch 550 – loss: 9.9054 - fPC 0.9971, 0.9925\n",
      "Epoch 560 – loss: 9.7607 - fPC 0.9971, 0.9925\n",
      "Epoch 570 – loss: 9.6387 - fPC 0.9971, 0.9925\n",
      "Epoch 580 – loss: 9.5346 - fPC 0.9971, 0.9925\n",
      "Epoch 590 – loss: 9.4454 - fPC 0.9971, 0.9925\n",
      "Epoch 600 – loss: 9.3690 - fPC 0.9971, 0.9925\n",
      "Epoch 610 – loss: 9.3042 - fPC 0.9971, 0.9925\n",
      "Epoch 620 – loss: 9.2491 - fPC 0.9971, 0.9925\n",
      "Epoch 630 – loss: 9.2023 - fPC 0.9971, 0.9925\n",
      "Epoch 640 – loss: 9.1626 - fPC 0.9971, 0.9925\n",
      "Epoch 650 – loss: 9.1287 - fPC 0.9971, 0.9925\n",
      "Epoch 660 – loss: 9.0996 - fPC 0.9971, 0.9925\n",
      "Epoch 670 – loss: 9.0745 - fPC 0.9971, 0.9925\n",
      "Epoch 680 – loss: 9.0527 - fPC 0.9971, 0.9925\n",
      "Epoch 690 – loss: 9.0335 - fPC 0.9971, 0.9925\n",
      "Epoch 700 – loss: 9.0167 - fPC 0.9971, 0.9925\n",
      "Epoch 710 – loss: 9.0017 - fPC 0.9971, 0.9925\n",
      "Epoch 720 – loss: 8.9884 - fPC 0.9971, 0.9925\n",
      "Epoch 730 – loss: 8.9764 - fPC 0.9971, 0.9925\n",
      "Epoch 740 – loss: 8.9656 - fPC 0.9971, 0.9925\n",
      "Epoch 750 – loss: 8.9558 - fPC 0.9971, 0.9925\n",
      "Epoch 760 – loss: 8.9469 - fPC 0.9971, 0.9925\n",
      "Epoch 770 – loss: 8.9388 - fPC 0.9971, 0.9925\n",
      "Epoch 780 – loss: 8.9313 - fPC 0.9971, 0.9925\n",
      "Epoch 790 – loss: 8.9244 - fPC 0.9971, 0.9925\n",
      "Epoch 800 – loss: 8.9180 - fPC 0.9971, 0.9925\n",
      "Epoch 810 – loss: 8.9122 - fPC 0.9971, 0.9925\n",
      "Epoch 820 – loss: 8.9067 - fPC 0.9971, 0.9925\n",
      "Epoch 830 – loss: 8.9016 - fPC 0.9971, 0.9925\n",
      "Epoch 840 – loss: 8.8968 - fPC 0.9971, 0.9925\n",
      "Epoch 850 – loss: 8.8924 - fPC 0.9971, 0.9925\n",
      "Epoch 860 – loss: 8.8882 - fPC 0.9971, 0.9925\n",
      "Epoch 870 – loss: 8.8843 - fPC 0.9971, 0.9925\n",
      "Epoch 880 – loss: 8.8806 - fPC 0.9971, 0.9925\n",
      "Epoch 890 – loss: 8.8771 - fPC 0.9971, 0.9925\n",
      "Epoch 900 – loss: 8.8738 - fPC 0.9971, 0.9925\n",
      "Epoch 910 – loss: 8.8707 - fPC 0.9971, 0.9925\n",
      "Epoch 920 – loss: 8.8677 - fPC 0.9971, 0.9925\n",
      "Epoch 930 – loss: 8.8649 - fPC 0.9971, 0.9925\n",
      "Epoch 940 – loss: 8.8623 - fPC 0.9971, 0.9925\n",
      "Epoch 950 – loss: 8.8597 - fPC 0.9971, 0.9925\n",
      "Epoch 960 – loss: 8.8573 - fPC 0.9971, 0.9925\n",
      "Epoch 970 – loss: 8.8550 - fPC 0.9971, 0.9925\n",
      "Epoch 980 – loss: 8.8528 - fPC 0.9971, 0.9925\n",
      "Epoch 990 – loss: 8.8507 - fPC 0.9971, 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BigModel(\n",
       "  (branch): TwoBranch(\n",
       "    (left): LSTM(3, 5, num_layers=2)\n",
       "    (right): LSTM(3, 5, num_layers=2)\n",
       "    (combine): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       "  (rest): Sequential(\n",
       "    (0): GELU(approximate='none')\n",
       "    (1): Linear(in_features=10, out_features=8, bias=True)\n",
       "    (2): GELU(approximate='none')\n",
       "    (3): Linear(in_features=8, out_features=4, bias=True)\n",
       "    (4): GELU(approximate='none')\n",
       "    (5): Linear(in_features=4, out_features=1, bias=True)\n",
       "    (6): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T04:01:10.873259Z",
     "start_time": "2025-12-11T04:01:10.819848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "def confusion_rates(yhat: torch.Tensor, y: torch.Tensor):\n",
    "    tp = (yhat == 1) & (y == 1)\n",
    "    tn = (yhat == 0) & (y == 0)\n",
    "    fp = (yhat == 1) & (y == 0)\n",
    "    fn = (yhat == 0) & (y == 1)\n",
    "\n",
    "    TP = int(tp.sum().item())\n",
    "    TN = int(tn.sum().item())\n",
    "    FP = int(fp.sum().item())\n",
    "    FN = int(fn.sum().item())\n",
    "\n",
    "    eps = 1e-12\n",
    "    TPR = TP / (TP + FN + eps)   # recall / sensitivity\n",
    "    TNR = TN / (TN + FP + eps)   # specificity\n",
    "    FPR = FP / (FP + TN + eps)   # 1 - specificity\n",
    "    FNR = FN / (FN + TP + eps)   # 1 - recall\n",
    "\n",
    "    return {\"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
    "            \"TPR\": TPR, \"TNR\": TNR, \"FPR\": FPR, \"FNR\": FNR}\n",
    "\n",
    "def metrics():\n",
    "    yhat = model2(leftTest, rightTest).round().int()\n",
    "    y = yTest\n",
    "    return confusion_rates(yhat, y)\n",
    "\n",
    "res = metrics()\n",
    "\n",
    "print(f\"True Positive Rate (Recall) : {res['TPR']:.4f}\")\n",
    "print(f\"True Negative Rate (Spec.)  : {res['TNR']:.4f}\")\n",
    "print(f\"False Positive Rate         : {res['FPR']:.4f}\")\n",
    "print(f\"False Negative Rate         : {res['FNR']:.4f}\")\n"
   ],
   "id": "a2ffde47d0a4b526",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate (Recall) : 1.0000\n",
      "True Negative Rate (Spec.)  : 0.9941\n",
      "False Positive Rate         : 0.0059\n",
      "False Negative Rate         : 0.0000\n"
     ]
    }
   ],
   "execution_count": 52
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
